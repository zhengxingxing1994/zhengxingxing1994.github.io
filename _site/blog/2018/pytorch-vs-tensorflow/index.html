<!DOCTYPE html>
<html lang="en">
  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
    <!-- Metadata, OpenGraph and Schema.org -->




<!-- Standard metadata -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<title>
  
  
    
      Pytorch VS Tensorflow | Liangliang Zheng
    
  
</title>
<meta name="author" content="Liangliang Zheng">
<meta name="description" content="Welcome to Liangliang's blog, where I share my thoughts and experiences on various topics.
">










<!-- Bootstrap & MDB -->
<link rel="stylesheet" href="/al-folio/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

<!-- Bootstrap Table -->


<!-- Fonts & Icons -->
<link defer rel="stylesheet" href="/al-folio/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5">
<link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap">

<!-- Code Syntax Highlighting -->
<link defer rel="stylesheet" href="/al-folio/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light">


  <!-- Sidebar Table of Contents -->
  <link defer href="/al-folio/assets/css/bootstrap-toc.min.css?6f5af0bb9aab25d79b2448143cbeaa88" rel="stylesheet">


<!-- Styles -->

<!-- pseudocode -->



  <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;">

<link rel="stylesheet" href="/al-folio/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e">
<link rel="canonical" href="http://0.0.0.0:8080/al-folio/blog/2018/pytorch-vs-tensorflow/">

<!-- Dark Mode -->
<script src="/al-folio/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script>

  <link defer rel="stylesheet" href="/al-folio/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark">
  <script>
    initTheme();
  </script>


<!-- GeoJSON support via Leaflet -->


<!-- diff2html -->






  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">
    <!-- Header -->
    <header>
  <!-- Nav Bar -->
  <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation">
    <div class="container">
      
        <a class="navbar-brand title font-weight-lighter" href="/al-folio/">
          
            
              <span class="font-weight-bold">Liangliang</span>
            
            
            Zheng
          
        </a>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>

      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          

          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/al-folio/">about
              
            </a>
          </li>

          <!-- Other pages -->
          
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
              
                <li class="nav-item ">
                  
                  <a class="nav-link" href="/al-folio/blog/">blog
                    
                  </a>
                </li>
              
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
              
                <li class="nav-item ">
                  
                  <a class="nav-link" href="/al-folio/repositories/">repositories
                    
                  </a>
                </li>
              
            
          
            
              
                <li class="nav-item ">
                  
                  <a class="nav-link" href="/al-folio/cv/">CV
                    
                  </a>
                </li>
              
            
          
            
              
                
                
                <li class="nav-item dropdown ">
                  <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">archive
                    
                  </a>
                  <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown">
                    
                      
                        <a class="dropdown-item " href="/al-folio/archive_by_year">by year</a>
                      
                    
                      
                        <a class="dropdown-item " href="/al-folio/archive_by_tag">by category</a>
                      
                    
                  </div>
                </li>
              
            
          
          
            <!-- Search -->
            <li class="nav-item">
              <button id="search-toggle" title="Search" onclick="openSearchModal()">
                <span class="nav-link">ctrl k <i class="ti ti-search"></i></span>
              </button>
            </li>
          
          
            <!-- Toogle theme mode -->
            <li class="toggle-container">
              <button id="light-toggle" title="Change theme">
                <i class="ti ti-sun-moon" id="light-toggle-system"></i>
                <i class="ti ti-moon-filled" id="light-toggle-dark"></i>
                <i class="ti ti-sun-filled" id="light-toggle-light"></i>
              </button>
            </li>
          
        </ul>
      </div>
    </div>
  </nav>
  
    <!-- Scrolling Progress Bar -->
    <progress id="progress" value="0">
      <div class="progress-container">
        <span class="progress-bar"></span>
      </div>
    </progress>
  
</header>


    <!-- Content -->
    <div class="container mt-5" role="main">
      
        
          <div class="row">
            <!-- sidebar, which will move to the top on a small screen -->
            <div class="col-sm-3">
              <nav id="toc-sidebar" class="sticky-top"></nav>
            </div>
            <!-- main content area -->
            <div class="col-sm-9">







<div class="post">
  <header class="post-header">
    <h1 class="post-title">Pytorch VS Tensorflow</h1>
    <p class="post-meta">
      Created in July 31, 2018
      
      
      
    </p>
    <p class="post-tags">
      
        <a href="/al-folio/blog/2018"> <i class="fa-solid fa-calendar fa-sm"></i> 2018 </a>
      
      

      
          ·  
        
          
            <a href="/al-folio/blog/category/dl-ml-python">
              <i class="fa-solid fa-tag fa-sm"></i> dl-ml-python</a>
          
          
        
      
    </p>
  </header>

  <article class="post-content">
    
    <div id="markdown-content">
      <p>Right now Pytorch and Tensorflow are the extremely popular AI frameworks , but AI researchers may find it a little bit tangled when it comes to the question that which framework to use. So rather than choose one of them to learn, why not use both of them since they will come in handy later on. So I’m going to introduce both of them from the perspective of  vanilla structure and API.</p>

<h3 id="pytorch"><strong>Pytorch</strong></h3>

<p>A PyTorch Tensor is conceptionally similar to a numpy array: it is an n-dimensional grid of numbers, and like numpy PyTorch provides many functions to efficiently operate on Tensors.</p>

<p>all of the packages we import in this blog for pytorch part:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="mi">1</span> <span class="kn">import</span> <span class="n">torch</span>
 <span class="mi">2</span> <span class="kn">import</span> <span class="n">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
 <span class="mi">3</span> <span class="kn">import</span> <span class="n">torch.optim</span> <span class="k">as</span> <span class="n">optim</span>
 <span class="mi">4</span> <span class="kn">from</span> <span class="n">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
 <span class="mi">5</span> <span class="kn">from</span> <span class="n">torch.utils.data</span> <span class="kn">import</span> <span class="n">sampler</span>
 <span class="mi">6</span> 
 <span class="mi">7</span> <span class="kn">import</span> <span class="n">torchvision.datasets</span> <span class="k">as</span> <span class="n">dset</span>
 <span class="mi">8</span> <span class="kn">import</span> <span class="n">torchvision.transforms</span> <span class="k">as</span> <span class="n">T</span>
 <span class="mi">9</span> 
<span class="mi">10</span> <span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
</code></pre></div></div>

<p>Image data is typically stored in a Tensor shape x = N * C * H * W</p>

<ul>
  <li>N is the number of datapoints</li>
  <li>C is the number of channels</li>
  <li>H is the height of the intermediate feature map in pixels</li>
  <li>W is the height of the intermediate feature map in pixels</li>
</ul>

<p>When we process the fully connected layer, we need to flatten the C * H *W values into a single vector per image</p>

<p>1 def flatten(x):
 2    N = x.shape[0] # read in N, C, H, W
 3    return x.view(N, -1)  # “flatten” the C * H * W values into a single vector per image</p>

<p><strong>Three-layer network </strong> Implement a vanilla structure of three-layer netwok, and the architecture will be as follows:</p>

<ol>
  <li>A convolutional layer (with bias) with <code class="language-plaintext highlighter-rouge">channel_1</code> filters, each with shape <code class="language-plaintext highlighter-rouge">KW1 x KH1</code>, and zero-padding of two</li>
  <li>ReLU nonlinearity</li>
  <li>A convolutional layer (with bias) with <code class="language-plaintext highlighter-rouge">channel_2</code> filters, each with shape <code class="language-plaintext highlighter-rouge">KW2 x KH2</code>, and zero-padding of one</li>
  <li>ReLU nonlinearity</li>
  <li>Fully-connected layer with bias, producing scores for C classes.</li>
</ol>

<p>Nomally, the function contains 2 parameters, which are input x and params, and the params are specified based on how many layers and what type of architecture you’re using.</p>

<p>Notice that this architecture includes 2 convolutional layer, we need the conv2d function from torch.nn.functional.conv2d<img src="https://zhengliangliang.files.wordpress.com/2018/07/2018-07-31_123127.jpg" alt="2018-07-31_123127.jpg"></p>

<p>And the core functions are conv2d,relu and mm</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="mi">1</span> <span class="k">def</span> <span class="nf">three_layer_convnet</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
 <span class="mi">2</span>    <span class="sh">"""</span><span class="s">
 3    Performs the forward pass of a three-layer convolutional network with the
 4    architecture defined above.
 5 
 6    Inputs:
 7    - x: A PyTorch Tensor of shape (N, 3, H, W) giving a minibatch of images
 8    - params: A list of PyTorch Tensors giving the weights and biases for the
 9      network; should contain the following:
10       - conv_w1: PyTorch Tensor of shape (channel_1, 3, KH1, KW1) giving weights
11         for the first convolutional layer
12       - conv_b1: PyTorch Tensor of shape (channel_1,) giving biases for the first
13         convolutional layer
14       - conv_w2: PyTorch Tensor of shape (channel_2, channel_1, KH2, KW2) giving
15         weights for the second convolutional layer
16       - conv_b2: PyTorch Tensor of shape (channel_2,) giving biases for the second
17         convolutional layer
18       - fc_w: PyTorch Tensor giving weights for the fully-connected layer. Can you
19         figure out what the shape should be?
20       - fc_b: PyTorch Tensor giving biases for the fully-connected layer. Can you
21         figure out what the shape should be?
22     
23     Returns:
24     - scores: PyTorch Tensor of shape (N, C) giving classification scores for x
25     </span><span class="sh">"""</span>
<span class="mi">26</span>     <span class="n">conv_w1</span><span class="p">,</span> <span class="n">conv_b1</span><span class="p">,</span> <span class="n">conv_w2</span><span class="p">,</span> <span class="n">conv_b2</span><span class="p">,</span> <span class="n">fc_w</span><span class="p">,</span> <span class="n">fc_b</span> <span class="o">=</span> <span class="n">params</span>
<span class="mi">27</span>     <span class="n">scores</span> <span class="o">=</span> <span class="bp">None</span>
<span class="mi">28</span>     <span class="c1">################################################################################
</span><span class="mi">29</span>     <span class="c1"># TODO: Implement the forward pass for the three-layer ConvNet.                #
</span><span class="mi">30</span>     <span class="c1">################################################################################
</span><span class="mi">31</span>     <span class="n">conv1</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">conv2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="n">conv_w1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">conv_b1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="mi">32</span>     <span class="n">relu1</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">relu</span><span class="p">(</span><span class="n">conv1</span><span class="p">)</span>
<span class="mi">33</span>     <span class="n">conv2</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">conv2d</span><span class="p">(</span><span class="n">relu1</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="n">conv_w2</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">conv_b2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="mi">34</span>     <span class="n">relu2</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">relu</span><span class="p">(</span><span class="n">conv2</span><span class="p">)</span>
<span class="mi">35</span>     <span class="n">relu2_flat</span> <span class="o">=</span> <span class="nf">flatten</span><span class="p">(</span><span class="n">relu2</span><span class="p">)</span>
<span class="mi">36</span>     <span class="n">scores</span> <span class="o">=</span> <span class="n">relu2_flat</span><span class="p">.</span><span class="nf">mm</span><span class="p">(</span><span class="n">fc_w</span><span class="p">)</span> <span class="o">+</span> <span class="n">fc_b</span>
<span class="mi">37</span>     <span class="c1">#pass
</span><span class="mi">38</span>     <span class="c1">################################################################################
</span><span class="mi">39</span>     <span class="c1">#                                 END OF YOUR CODE                             #
</span><span class="mi">40</span>     <span class="c1">################################################################################
</span><span class="mi">41</span>     <span class="k">return</span> <span class="n">scores</span>
</code></pre></div></div>
<p><strong>Pytorch Initialization :</strong></p>

<ul>
  <li>
<code class="language-plaintext highlighter-rouge">random_weight(shape)</code> initializes a weight tensor with the Kaiming normalization method.(normally do it with weights)</li>
  <li>
<code class="language-plaintext highlighter-rouge">zero_weight(shape)</code> initializes a weight tensor with all zeros. Useful for instantiating bias parameters.(normally do it with biases)
    <div class="language-python highlighter-rouge">
<div class="highlight"><pre class="highlight"><code> <span class="mi">1</span> <span class="k">def</span> <span class="nf">random_weight</span><span class="p">(</span><span class="n">shape</span><span class="p">):</span>
 <span class="mi">2</span>    <span class="sh">"""</span><span class="s">
 3    Create random Tensors for weights; setting requires_grad=True means that we
 4    want to compute gradients for these Tensors during the backward pass.
 5    We use Kaiming normalization: sqrt(2 / fan_in)
 6    </span><span class="sh">"""</span>
 <span class="mi">7</span>    <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>  <span class="c1"># FC weight
</span> <span class="mi">8</span>        <span class="n">fan_in</span> <span class="o">=</span> <span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
 <span class="mi">9</span>    <span class="k">else</span><span class="p">:</span>
<span class="mi">10</span>         <span class="n">fan_in</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">prod</span><span class="p">(</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span> <span class="c1"># conv weight [out_channel, in_channel, kH, kW]
</span><span class="mi">11</span>     <span class="c1"># randn is standard normal distribution generator. 
</span><span class="mi">12</span>     <span class="n">w</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="mf">2.</span> <span class="o">/</span> <span class="n">fan_in</span><span class="p">)</span>
<span class="mi">13</span>     <span class="n">w</span><span class="p">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="bp">True</span>
<span class="mi">14</span>     <span class="k">return</span> <span class="n">w</span>
<span class="mi">15</span> 
<span class="mi">16</span> <span class="k">def</span> <span class="nf">zero_weight</span><span class="p">(</span><span class="n">shape</span><span class="p">):</span>
<span class="mi">17</span>     <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="mi">18</span> 
<span class="mi">19</span> <span class="c1"># create a weight of shape [3 x 5]
</span><span class="mi">20</span> <span class="c1"># you should see the type `torch.cuda.FloatTensor` if you use GPU. 
</span><span class="mi">21</span> <span class="c1"># Otherwise it should be `torch.FloatTensor`
</span><span class="mi">22</span> <span class="nf">random_weight</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
</code></pre></div>    </div>
    <p><strong>PyTorch: Check Accuracy</strong></p>
  </li>
</ul>

<p>When checking accuracy we don’t need to compute any gradients; as a result we don’t need PyTorch to build a computational graph for us when we compute scores. To prevent a graph from being built we scope our computation under a <code class="language-plaintext highlighter-rouge">torch.no_grad()</code> context manager.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
 <span class="mi">1</span> <span class="k">def</span> <span class="nf">check_accuracy_part2</span><span class="p">(</span><span class="n">loader</span><span class="p">,</span> <span class="n">model_fn</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
 <span class="mi">2</span>    <span class="sh">"""</span><span class="s">
 3    Check the accuracy of a classification model.
 4    
 5    Inputs:
 6    - loader: A DataLoader for the data split we want to check
 7    - model_fn: A function that performs the forward pass of the model,
 8      with the signature scores = model_fn(x, params)
 9    - params: List of PyTorch Tensors giving parameters of the model
10     
11     Returns: Nothing, but prints the accuracy of the model
12     </span><span class="sh">"""</span>
<span class="mi">13</span>     <span class="n">split</span> <span class="o">=</span> <span class="sh">'</span><span class="s">val</span><span class="sh">'</span> <span class="k">if</span> <span class="n">loader</span><span class="p">.</span><span class="n">dataset</span><span class="p">.</span><span class="n">train</span> <span class="k">else</span> <span class="sh">'</span><span class="s">test</span><span class="sh">'</span>
<span class="mi">14</span>     <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Checking accuracy on the %s set</span><span class="sh">'</span> <span class="o">%</span> <span class="n">split</span><span class="p">)</span>
<span class="mi">15</span>     <span class="n">num_correct</span><span class="p">,</span> <span class="n">num_samples</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>
<span class="mi">16</span>     <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
<span class="mi">17</span>         <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">loader</span><span class="p">:</span>
<span class="mi">18</span>             <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>  <span class="c1"># move to device, e.g. GPU
</span><span class="mi">19</span>             <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">int64</span><span class="p">)</span>
<span class="mi">20</span>             <span class="n">scores</span> <span class="o">=</span> <span class="nf">model_fn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
<span class="mi">21</span>             <span class="n">_</span><span class="p">,</span> <span class="n">preds</span> <span class="o">=</span> <span class="n">scores</span><span class="p">.</span><span class="nf">max</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="mi">22</span>             <span class="n">num_correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">preds</span> <span class="o">==</span> <span class="n">y</span><span class="p">).</span><span class="nf">sum</span><span class="p">()</span>
<span class="mi">23</span>             <span class="n">num_samples</span> <span class="o">+=</span> <span class="n">preds</span><span class="p">.</span><span class="nf">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="mi">24</span>         <span class="n">acc</span> <span class="o">=</span> <span class="nf">float</span><span class="p">(</span><span class="n">num_correct</span><span class="p">)</span> <span class="o">/</span> <span class="n">num_samples</span>
<span class="mi">25</span>         <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Got %d / %d correct (%.2f%%)</span><span class="sh">'</span> <span class="o">%</span> <span class="p">(</span><span class="n">num_correct</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">,</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">acc</span><span class="p">))</span>
</code></pre></div></div>
<p><strong>PyTorch: Training Loop</strong></p>

<p>The final step is to train the model , firstly move the data to proper device and then compute the loss , then using SGD to compute the gradients. then call the check accuracy function to print out the accuracy</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="mi">1</span> <span class="k">def</span> <span class="nf">train_part2</span><span class="p">(</span><span class="n">model_fn</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">):</span>
 <span class="mi">2</span>    <span class="sh">"""</span><span class="s">
 3    Train a model on CIFAR-10.
 4    
 5    Inputs:
 6    - model_fn: A Python function that performs the forward pass of the model.
 7      It should have the signature scores = model_fn(x, params) where x is a
 8      PyTorch Tensor of image data, params is a list of PyTorch Tensors giving
 9      model weights, and scores is a PyTorch Tensor of shape (N, C) giving
10       scores for the elements in x.
11     - params: List of PyTorch Tensors giving weights for the model
12     - learning_rate: Python scalar giving the learning rate to use for SGD
13     
14     Returns: Nothing
15     </span><span class="sh">"""</span>
<span class="mi">16</span>     <span class="k">for</span> <span class="n">t</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">loader_train</span><span class="p">):</span>
<span class="mi">17</span>         <span class="c1"># Move the data to the proper device (GPU or CPU)
</span><span class="mi">18</span>         <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
<span class="mi">19</span>         <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nb">long</span><span class="p">)</span>
<span class="mi">20</span> 
<span class="mi">21</span>         <span class="c1"># Forward pass: compute scores and loss
</span><span class="mi">22</span>         <span class="n">scores</span> <span class="o">=</span> <span class="nf">model_fn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
<span class="mi">23</span>         <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">cross_entropy</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="mi">24</span> 
<span class="mi">25</span>         <span class="c1"># Backward pass: PyTorch figures out which Tensors in the computational
</span><span class="mi">26</span>         <span class="c1"># graph has requires_grad=True and uses backpropagation to compute the
</span><span class="mi">27</span>         <span class="c1"># gradient of the loss with respect to these Tensors, and stores the
</span><span class="mi">28</span>         <span class="c1"># gradients in the .grad attribute of each Tensor.
</span><span class="mi">29</span>         <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>
<span class="mi">30</span> 
<span class="mi">31</span>         <span class="c1"># Update parameters. We don't want to backpropagate through the
</span><span class="mi">32</span>         <span class="c1"># parameter updates, so we scope the updates under a torch.no_grad()
</span><span class="mi">33</span>         <span class="c1"># context manager to prevent a computational graph from being built.
</span><span class="mi">34</span>         <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
<span class="mi">35</span>             <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>
<span class="mi">36</span>                 <span class="n">w</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">w</span><span class="p">.</span><span class="n">grad</span>
<span class="mi">37</span> 
<span class="mi">38</span>                 <span class="c1"># Manually zero the gradients after running the backward pass
</span><span class="mi">39</span>                 <span class="n">w</span><span class="p">.</span><span class="n">grad</span><span class="p">.</span><span class="nf">zero_</span><span class="p">()</span>
<span class="mi">40</span> 
<span class="mi">41</span>         <span class="k">if</span> <span class="n">t</span> <span class="o">%</span> <span class="n">print_every</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
<span class="mi">42</span>             <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Iteration %d, loss = %.4f</span><span class="sh">'</span> <span class="o">%</span> <span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">loss</span><span class="p">.</span><span class="nf">item</span><span class="p">()))</span>
<span class="mi">43</span>             <span class="nf">check_accuracy_part2</span><span class="p">(</span><span class="n">loader_val</span><span class="p">,</span> <span class="n">model_fn</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
<span class="mi">44</span>             <span class="nf">print</span><span class="p">()</span>
</code></pre></div></div>
<p>To sum up, the whole process will be 1. Initialize hidden layer size and learning rate,weights 2. Passing data and params( in train function) to three_layer_convnet 3. After computing the scores,then calculate the cross entropy loss and start backward part and upgrating weights(SGD) 4. finally print out the accuracy</p>

<h3 id="module-api-2-layer-network"><strong>Module API: 2-layer network:</strong></h3>

<p>Barebone PyTorch requires that we track all the parameter tensors by hand. This is fine for small networks with a few tensors, but it would be extremely inconvenient and error-prone to track tens or hundreds of tensors in larger networks.</p>

<p>To use the Module API, follow the steps below:</p>

<ol>
  <li>Subclass <code class="language-plaintext highlighter-rouge">nn.Module</code>. Give your network class an intuitive name like <code class="language-plaintext highlighter-rouge">TwoLayerFC</code>.</li>
  <li>In the constructor <code class="language-plaintext highlighter-rouge">__init__()</code>, define all the layers you need as class attributes. Layer objects like <code class="language-plaintext highlighter-rouge">nn.Linear</code> and <code class="language-plaintext highlighter-rouge">nn.Conv2d</code> are themselves <code class="language-plaintext highlighter-rouge">nn.Module</code> subclasses and contain learnable parameters, so that you don’t have to instantiate the raw tensors yourself. <code class="language-plaintext highlighter-rouge">nn.Module</code> will track these internal parameters for you. Refer to the <a href="http://pytorch.org/docs/master/nn.html" rel="external nofollow noopener" target="_blank">doc</a> to learn more about the dozens of builtin layers. <strong>Warning</strong>: don’t forget to call the <code class="language-plaintext highlighter-rouge">super().__init__()</code> first!</li>
  <li>In the <code class="language-plaintext highlighter-rouge">forward()</code> method, define the <em>connectivity</em> of your network. You should use the attributes defined in <code class="language-plaintext highlighter-rouge">__init__</code> as function calls that take tensor as input and output the “transformed” tensor. Do <em>not</em> create any new layers with learnable parameters in <code class="language-plaintext highlighter-rouge">forward()</code>! All of them must be declared upfront in <code class="language-plaintext highlighter-rouge">__init__</code>.</li>
</ol>

<p>Example for following architecture:</p>

<ol>
  <li>Convolutional layer with <code class="language-plaintext highlighter-rouge">channel_1</code> 5x5 filters with zero-padding of 2</li>
  <li>ReLU</li>
  <li>Convolutional layer with <code class="language-plaintext highlighter-rouge">channel_2</code> 3x3 filters with zero-padding of 1</li>
  <li>ReLU</li>
  <li>Fully-connected layer to <code class="language-plaintext highlighter-rouge">num_classes</code> classes</li>
</ol>

<p>and all of the functions are from nn.Module, in the init funcution , we setup the layers information, and there are kaiming_normal and constant initilization function in the nn.Module</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="mi">1</span> <span class="k">class</span> <span class="nc">ThreeLayerConvNet</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
 <span class="mi">2</span>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">in_channel</span><span class="p">,</span> <span class="n">channel_1</span><span class="p">,</span> <span class="n">channel_2</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">):</span>
 <span class="mi">3</span>        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
 <span class="mi">4</span>        <span class="c1">########################################################################
</span> <span class="mi">5</span>        <span class="c1"># TODO: Set up the layers you need for a three-layer ConvNet with the  #
</span> <span class="mi">6</span>        <span class="c1"># architecture defined above.                                          #
</span> <span class="mi">7</span>        <span class="c1">########################################################################
</span> <span class="mi">8</span>        <span class="n">self</span><span class="p">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Conv2d</span><span class="p">(</span><span class="n">in_channel</span><span class="p">,</span><span class="n">channel_1</span><span class="p">,</span><span class="n">kernel_size</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span><span class="n">padding</span> <span class="o">=</span><span class="mi">2</span><span class="p">,</span><span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
 <span class="mi">9</span>        <span class="n">nn</span><span class="p">.</span><span class="n">init</span><span class="p">.</span><span class="nf">kaiming_normal_</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">conv1</span><span class="p">.</span><span class="n">weight</span><span class="p">)</span>
<span class="mi">10</span>         <span class="n">nn</span><span class="p">.</span><span class="n">init</span><span class="p">.</span><span class="nf">constant_</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">conv1</span><span class="p">.</span><span class="n">bias</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span>
<span class="mi">11</span>         
<span class="mi">12</span>         <span class="n">self</span><span class="p">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Conv2d</span><span class="p">(</span><span class="n">channel_1</span><span class="p">,</span><span class="n">channel_2</span><span class="p">,</span><span class="n">kernel_size</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span><span class="n">padding</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span><span class="n">bias</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
<span class="mi">13</span>         <span class="n">nn</span><span class="p">.</span><span class="n">init</span><span class="p">.</span><span class="nf">kaiming_normal_</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">conv1</span><span class="p">.</span><span class="n">weight</span><span class="p">)</span>
<span class="mi">14</span>         <span class="n">nn</span><span class="p">.</span><span class="n">init</span><span class="p">.</span><span class="nf">constant_</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">conv1</span><span class="p">.</span><span class="n">bias</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span>
<span class="mi">15</span>         
<span class="mi">16</span>         <span class="n">self</span><span class="p">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">channel_2</span><span class="o">*</span><span class="mi">32</span><span class="o">*</span><span class="mi">32</span><span class="p">,</span><span class="n">num_classes</span><span class="p">)</span>
<span class="mi">17</span>         <span class="n">nn</span><span class="p">.</span><span class="n">init</span><span class="p">.</span><span class="nf">kaiming_normal_</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">fc</span><span class="p">.</span><span class="n">weight</span><span class="p">)</span>
<span class="mi">18</span>         <span class="n">nn</span><span class="p">.</span><span class="n">init</span><span class="p">.</span><span class="nf">constant_</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">fc</span><span class="p">.</span><span class="n">bias</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="mi">19</span>         
<span class="mi">20</span>         <span class="c1">#pass
</span><span class="mi">21</span>         <span class="c1">########################################################################
</span><span class="mi">22</span>         <span class="c1">#                          END OF YOUR CODE                            # 
</span><span class="mi">23</span>         <span class="c1">########################################################################
</span><span class="mi">24</span> 
<span class="mi">25</span>     <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="mi">26</span>         <span class="n">scores</span> <span class="o">=</span> <span class="bp">None</span>
<span class="mi">27</span>         <span class="c1">########################################################################
</span><span class="mi">28</span>         <span class="c1"># TODO: Implement the forward function for a 3-layer ConvNet. you      #
</span><span class="mi">29</span>         <span class="c1"># should use the layers you defined in __init__ and specify the        #
</span><span class="mi">30</span>         <span class="c1"># connectivity of those layers in forward()                            #
</span><span class="mi">31</span>         <span class="c1">########################################################################
</span><span class="mi">32</span>         <span class="n">relu1</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">relu</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="mi">33</span>         <span class="n">relu2</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">relu</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">conv2</span><span class="p">(</span><span class="n">relu1</span><span class="p">))</span>
<span class="mi">34</span>         <span class="n">scores</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">fc</span><span class="p">(</span><span class="nf">flatten</span><span class="p">(</span><span class="n">relu2</span><span class="p">))</span>
<span class="mi">35</span>         <span class="c1">#pass
</span><span class="mi">36</span>         <span class="c1">########################################################################
</span><span class="mi">37</span>         <span class="c1">#                             END OF YOUR CODE                         #
</span><span class="mi">38</span>         <span class="c1">########################################################################
</span><span class="mi">39</span>         <span class="k">return</span> <span class="n">scores</span>
</code></pre></div></div>
<p><strong>Module API: Check Accuracy</strong> This version is slightly different from the one in part II. You don’t manually pass in the parameters anymore.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="mi">1</span> <span class="k">def</span> <span class="nf">check_accuracy_part34</span><span class="p">(</span><span class="n">loader</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
 <span class="mi">2</span>    <span class="k">if</span> <span class="n">loader</span><span class="p">.</span><span class="n">dataset</span><span class="p">.</span><span class="n">train</span><span class="p">:</span>
 <span class="mi">3</span>        <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Checking accuracy on validation set</span><span class="sh">'</span><span class="p">)</span>
 <span class="mi">4</span>    <span class="k">else</span><span class="p">:</span>
 <span class="mi">5</span>        <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Checking accuracy on test set</span><span class="sh">'</span><span class="p">)</span>   
 <span class="mi">6</span>    <span class="n">num_correct</span> <span class="o">=</span> <span class="mi">0</span>
 <span class="mi">7</span>    <span class="n">num_samples</span> <span class="o">=</span> <span class="mi">0</span>
 <span class="mi">8</span>    <span class="n">model</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>  <span class="c1"># set model to evaluation mode
</span> <span class="mi">9</span>    <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
<span class="mi">10</span>         <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">loader</span><span class="p">:</span>
<span class="mi">11</span>             <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>  <span class="c1"># move to device, e.g. GPU
</span><span class="mi">12</span>             <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nb">long</span><span class="p">)</span>
<span class="mi">13</span>             <span class="n">scores</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="mi">14</span>             <span class="n">_</span><span class="p">,</span> <span class="n">preds</span> <span class="o">=</span> <span class="n">scores</span><span class="p">.</span><span class="nf">max</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="mi">15</span>             <span class="n">num_correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">preds</span> <span class="o">==</span> <span class="n">y</span><span class="p">).</span><span class="nf">sum</span><span class="p">()</span>
<span class="mi">16</span>             <span class="n">num_samples</span> <span class="o">+=</span> <span class="n">preds</span><span class="p">.</span><span class="nf">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="mi">17</span>         <span class="n">acc</span> <span class="o">=</span> <span class="nf">float</span><span class="p">(</span><span class="n">num_correct</span><span class="p">)</span> <span class="o">/</span> <span class="n">num_samples</span>
<span class="mi">18</span>         <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Got %d / %d correct (%.2f)</span><span class="sh">'</span> <span class="o">%</span> <span class="p">(</span><span class="n">num_correct</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">,</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">acc</span><span class="p">))</span>
</code></pre></div></div>
<p><strong>Module API : Training Loop</strong></p>

<p>We also use a slightly different training loop. Rather than updating the values of the weights ourselves, we use an Optimizer object from the <code class="language-plaintext highlighter-rouge">torch.optim</code> package, which abstract the notion of an optimization algorithm and provides implementations of most of the algorithms commonly used to optimize neural networks.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="mi">1</span> <span class="k">def</span> <span class="nf">train_part34</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
 <span class="mi">2</span>    <span class="sh">"""</span><span class="s">
 3    Train a model on CIFAR-10 using the PyTorch Module API.
 4    
 5    Inputs:
 6    - model: A PyTorch Module giving the model to train.
 7    - optimizer: An Optimizer object we will use to train the model
 8    - epochs: (Optional) A Python integer giving the number of epochs to train for
 9    
10     Returns: Nothing, but prints model accuracies during training.
11     </span><span class="sh">"""</span>
<span class="mi">12</span>     <span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># move the model parameters to CPU/GPU
</span><span class="mi">13</span>     <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
<span class="mi">14</span>         <span class="k">for</span> <span class="n">t</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">loader_train</span><span class="p">):</span>
<span class="mi">15</span>             <span class="n">model</span><span class="p">.</span><span class="nf">train</span><span class="p">()</span>  <span class="c1"># put model to training mode
</span><span class="mi">16</span>             <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>  <span class="c1"># move to device, e.g. GPU
</span><span class="mi">17</span>             <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nb">long</span><span class="p">)</span>
<span class="mi">18</span> 
<span class="mi">19</span>             <span class="n">scores</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="mi">20</span>             <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">cross_entropy</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="mi">21</span> 
<span class="mi">22</span>             <span class="c1"># Zero out all of the gradients for the variables which the optimizer
</span><span class="mi">23</span>             <span class="c1"># will update.
</span><span class="mi">24</span>             <span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>
<span class="mi">25</span> 
<span class="mi">26</span>             <span class="c1"># This is the backwards pass: compute the gradient of the loss with
</span><span class="mi">27</span>             <span class="c1"># respect to each  parameter of the model.
</span><span class="mi">28</span>             <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>
<span class="mi">29</span> 
<span class="mi">30</span>             <span class="c1"># Actually update the parameters of the model using the gradients
</span><span class="mi">31</span>             <span class="c1"># computed by the backwards pass.
</span><span class="mi">32</span>             <span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>
<span class="mi">33</span> 
<span class="mi">34</span>             <span class="k">if</span> <span class="n">t</span> <span class="o">%</span> <span class="n">print_every</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
<span class="mi">35</span>                 <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Iteration %d, loss = %.4f</span><span class="sh">'</span> <span class="o">%</span> <span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">loss</span><span class="p">.</span><span class="nf">item</span><span class="p">()))</span>
<span class="mi">36</span>                 <span class="nf">check_accuracy_part34</span><span class="p">(</span><span class="n">loader_val</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
<span class="mi">37</span>                 <span class="nf">print</span><span class="p">()</span>
</code></pre></div></div>
<p>Sum up the Module API: 1.initialize learning rate and chennel_1,passing then through model and initilize weights and declare the architecture 2. passing values to optim.SGD, 3. training them</p>

<h3 id="pytorch-sequential-api"><strong>Pytorch Sequential API</strong></h3>

<p>Part III introduced the PyTorch Module API, which allows you to define arbitrary learnable layers and their connectivity.</p>

<p>For simple models like a stack of feed forward layers, you still need to go through 3 steps: subclass <code class="language-plaintext highlighter-rouge">nn.Module</code>, assign layers to class attributes in <code class="language-plaintext highlighter-rouge">__init__</code>, and call each layer one by one in <code class="language-plaintext highlighter-rouge">forward()</code>. Is there a more convenient way?</p>

<p>Fortunately, PyTorch provides a container Module called <code class="language-plaintext highlighter-rouge">nn.Sequential</code>, which merges the above steps into one. It is not as flexible as <code class="language-plaintext highlighter-rouge">nn.Module</code>, because you cannot specify more complex topology than a feed-forward stack, but it’s good enough for many use cases.</p>

<p>Three Layers: Using Sequential API</p>

<ol>
  <li>Convolutional layer (with bias) with 32 5x5 filters, with zero-padding of 2</li>
  <li>ReLU</li>
  <li>Convolutional layer (with bias) with 16 3x3 filters, with zero-padding of 1</li>
  <li>ReLU</li>
  <li>Fully-connected layer (with bias) to compute scores for 10 classes</li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="mi">1</span> <span class="n">channel_1</span> <span class="o">=</span> <span class="mi">32</span>
 <span class="mi">2</span> <span class="n">channel_2</span> <span class="o">=</span> <span class="mi">16</span>
 <span class="mi">3</span> <span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">1e-2</span>
 <span class="mi">4</span> 
 <span class="mi">5</span> <span class="n">model</span> <span class="o">=</span> <span class="bp">None</span>
 <span class="mi">6</span> <span class="n">optimizer</span> <span class="o">=</span> <span class="bp">None</span>
 <span class="mi">7</span> 
 <span class="mi">8</span> <span class="c1">################################################################################
</span> <span class="mi">9</span> <span class="c1"># TODO: Rewrite the 2-layer ConvNet with bias from Part III with the           #
</span><span class="mi">10</span> <span class="c1"># Sequential API.                                                              #
</span><span class="mi">11</span> <span class="c1">################################################################################
</span><span class="mi">12</span> <span class="c1">#pass
</span><span class="mi">13</span> <span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">(</span>
<span class="mi">14</span>     <span class="n">nn</span><span class="p">.</span><span class="nc">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="n">channel_1</span><span class="p">,</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span><span class="n">padding</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
<span class="mi">15</span>     <span class="n">nn</span><span class="p">.</span><span class="nc">ReLU</span><span class="p">(),</span>
<span class="mi">16</span>     <span class="n">nn</span><span class="p">.</span><span class="nc">Conv2d</span><span class="p">(</span><span class="n">channel_1</span><span class="p">,</span><span class="n">channel_2</span><span class="p">,</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span><span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
<span class="mi">17</span>     <span class="n">nn</span><span class="p">.</span><span class="nc">ReLU</span><span class="p">(),</span>
<span class="mi">18</span>     <span class="nc">Flatten</span><span class="p">(),</span>
<span class="mi">19</span>     <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">channel_2</span><span class="o">*</span><span class="mi">32</span><span class="o">*</span><span class="mi">32</span><span class="p">,</span><span class="mi">10</span><span class="p">)</span>
<span class="mi">20</span> <span class="p">)</span>
<span class="mi">21</span> 
<span class="mi">22</span> <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="p">.</span><span class="nc">SGD</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span><span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span>
<span class="mi">23</span>                      <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span><span class="n">nesterov</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="mi">24</span> <span class="c1">################################################################################
</span><span class="mi">25</span> <span class="c1">#                                 END OF YOUR CODE 
</span><span class="mi">26</span> <span class="c1">################################################################################
</span><span class="mi">27</span> 
<span class="mi">28</span> <span class="nf">train_part34</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">)</span>
</code></pre></div></div>
<p>Using training_part34 and Sequential API, it’s super easy to set to the layers and transported the data to be trained: Finally the accuracy result will be:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> 1 Iteration 0, loss = 2.2939
 2 Checking accuracy on validation set
 3 Got 140 / 1000 correct (14.00)
 4 
 5 Iteration 100, loss = 1.4576
 6 Checking accuracy on validation set
 7 Got 471 / 1000 correct (47.10)
 8 
 9 Iteration 200, loss = 1.3825
10 Checking accuracy on validation set
11 Got 466 / 1000 correct (46.60)
12 
13 Iteration 300, loss = 1.5948
14 Checking accuracy on validation set
15 Got 524 / 1000 correct (52.40)
16 
17 Iteration 400, loss = 1.2816
18 Checking accuracy on validation set
19 Got 513 / 1000 correct (51.30)
20 
21 Iteration 500, loss = 1.3663
22 Checking accuracy on validation set
23 Got 530 / 1000 correct (53.00)
24 
25 Iteration 600, loss = 1.1300
26 Checking accuracy on validation set
27 Got 545 / 1000 correct (54.50)
28 
29 Iteration 700, loss = 1.2276
30 Checking accuracy on validation set
31 Got 542 / 1000 correct (54.20)

* * *
</code></pre></div></div>
<h3 id="tensorflow"><strong>Tensorflow</strong></h3>

<p>In this Tensorflow introduction, we gonna do the same structure as we do in the introduction of Pytorch</p>

<p><img src="https://zhengliangliang.files.wordpress.com/2018/07/2018-07-31_135946.jpg" alt="2018-07-31_135946.jpg"></p>

<p>All of the packages we imported:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="mi">1</span> <span class="kn">import</span> <span class="n">os</span>
 <span class="mi">2</span> <span class="kn">import</span> <span class="n">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
 <span class="mi">3</span> <span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
 <span class="mi">4</span> <span class="kn">import</span> <span class="n">math</span>
 <span class="mi">5</span> <span class="kn">import</span> <span class="n">timeit</span>
 <span class="mi">6</span> <span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
 <span class="mi">7</span> 
 <span class="mi">8</span> <span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
</code></pre></div></div>
<p><strong>Barebone Tensorflow:</strong></p>

<p>We can see this in action by defining a simple <code class="language-plaintext highlighter-rouge">flatten</code> function that will reshape image data for use in a fully-connected network.</p>

<p>In TensorFlow, data for convolutional feature maps is typically stored in a Tensor of shape N x H x W x C where:</p>

<ul>
  <li>N is the number of datapoints (minibatch size)</li>
  <li>H is the height of the feature map</li>
  <li>W is the width of the feature map</li>
  <li>C is the number of channels in the feature map</li>
</ul>

<p>Notice that this is a little different from pytorch.</p>

<p><strong>Three_layer_convnet</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="mi">1</span> <span class="k">def</span> <span class="nf">three_layer_convnet</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
 <span class="mi">2</span>    <span class="sh">"""</span><span class="s">
 3    A three-layer convolutional network with the architecture described above.
 4    
 5    Inputs:
 6    - x: A TensorFlow Tensor of shape (N, H, W, 3) giving a minibatch of images
 7    - params: A list of TensorFlow Tensors giving the weights and biases for the
 8      network; should contain the following:
 9      - conv_w1: TensorFlow Tensor of shape (KH1, KW1, 3, channel_1) giving
10         weights for the first convolutional layer.
11       - conv_b1: TensorFlow Tensor of shape (channel_1,) giving biases for the
12         first convolutional layer.
13       - conv_w2: TensorFlow Tensor of shape (KH2, KW2, channel_1, channel_2)
14         giving weights for the second convolutional layer
15       - conv_b2: TensorFlow Tensor of shape (channel_2,) giving biases for the
16         second convolutional layer.
17       - fc_w: TensorFlow Tensor giving weights for the fully-connected layer.
18         Can you figure out what the shape should be?
19       - fc_b: TensorFlow Tensor giving biases for the fully-connected layer.
20         Can you figure out what the shape should be?
21     </span><span class="sh">"""</span>
<span class="mi">22</span>     <span class="n">conv_w1</span><span class="p">,</span> <span class="n">conv_b1</span><span class="p">,</span> <span class="n">conv_w2</span><span class="p">,</span> <span class="n">conv_b2</span><span class="p">,</span> <span class="n">fc_w</span><span class="p">,</span> <span class="n">fc_b</span> <span class="o">=</span> <span class="n">params</span>
<span class="mi">23</span>     <span class="n">scores</span> <span class="o">=</span> <span class="bp">None</span>
<span class="mi">24</span>     <span class="c1">############################################################################
</span><span class="mi">25</span>     <span class="c1"># TODO: Implement the forward pass for the three-layer ConvNet.            #
</span><span class="mi">26</span>     <span class="c1">############################################################################
</span><span class="mi">27</span>     <span class="n">x_padded</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">pad</span><span class="p">(</span><span class="n">x</span><span class="p">,[[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],[</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">],[</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">],[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]],</span><span class="sh">'</span><span class="s">CONSTANT</span><span class="sh">'</span><span class="p">)</span>
<span class="mi">28</span>     <span class="n">conv1</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nf">conv2d</span><span class="p">(</span><span class="n">x_padded</span><span class="p">,</span><span class="n">conv_w1</span><span class="p">,[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span><span class="n">padding</span><span class="o">=</span><span class="sh">'</span><span class="s">VALID</span><span class="sh">'</span><span class="p">)</span><span class="o">+</span><span class="n">conv_b1</span>
<span class="mi">29</span>     <span class="n">relu1</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nf">relu</span><span class="p">(</span><span class="n">conv1</span><span class="p">)</span>
<span class="mi">30</span>     <span class="n">x_padded_1</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">pad</span><span class="p">(</span><span class="n">relu1</span><span class="p">,[[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]],</span><span class="sh">'</span><span class="s">CONSTANT</span><span class="sh">'</span><span class="p">)</span>
<span class="mi">31</span>     <span class="n">conv2</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nf">conv2d</span><span class="p">(</span><span class="n">x_padded_1</span><span class="p">,</span><span class="n">conv_w2</span><span class="p">,[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span><span class="n">padding</span><span class="o">=</span><span class="sh">'</span><span class="s">VALID</span><span class="sh">'</span><span class="p">)</span><span class="o">+</span><span class="n">conv_b2</span>
<span class="mi">32</span>     <span class="n">relu2</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nf">relu</span><span class="p">(</span><span class="n">conv2</span><span class="p">)</span>
<span class="mi">33</span>     <span class="n">fc_x</span> <span class="o">=</span> <span class="nf">flatten</span><span class="p">(</span><span class="n">relu2</span><span class="p">)</span>
<span class="mi">34</span>     <span class="n">h</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">matmul</span><span class="p">(</span><span class="n">fc_x</span><span class="p">,</span> <span class="n">fc_w</span><span class="p">)</span> <span class="o">+</span> <span class="n">fc_b</span>
<span class="mi">35</span>     <span class="n">scores</span> <span class="o">=</span> <span class="n">h</span>
<span class="mi">36</span>     <span class="c1">#pass
</span><span class="mi">37</span>     <span class="c1">############################################################################
</span><span class="mi">38</span>     <span class="c1">#                              END OF YOUR CODE                            #
</span><span class="mi">39</span>     <span class="c1">############################################################################
</span><span class="mi">40</span>     <span class="k">return</span> <span class="n">scores</span>
</code></pre></div></div>
<p>All of the functions are from tf.nn . From the above code you may find it very similar to pytorch, but we need to declear the padded form in tf.pad then pass them in tf.nn.conv2d function, and the stride parameter would be like [1,1,1,1]</p>

<p>Training step:</p>

<ol>
  <li>Compute the loss</li>
  <li>Compute the gradient of the loss with respect to all network weights</li>
  <li>Make a weight update step using (stochastic) gradient descent.</li>
</ol>

<p>Note that the step of updating the weights is itself an operation in the computational graph - the calls to <code class="language-plaintext highlighter-rouge">tf.assign_sub</code> in <code class="language-plaintext highlighter-rouge">training_step</code> return TensorFlow operations that mutate the weights when they are executed. There is an important bit of subtlety here - when we call <code class="language-plaintext highlighter-rouge">sess.run</code>, TensorFlow does not execute all operations in the computational graph; it only executes the minimal subset of the graph necessary to compute the outputs that we ask TensorFlow to produce. As a result, naively computing the loss would not cause the weight update operations to execute, <strong>since the operations needed to compute the loss do not depend on the output of the weight update</strong>. To fix this problem, we insert a <strong>control dependency</strong> into the graph, adding a duplicate <code class="language-plaintext highlighter-rouge">loss</code> node to the graph that does depend on the outputs of the weight update operations; this is the object that we actually return from the <code class="language-plaintext highlighter-rouge">training_step</code> function. As a result, asking TensorFlow to evaluate the value of the <code class="language-plaintext highlighter-rouge">loss</code>returned from <code class="language-plaintext highlighter-rouge">training_step</code> will also implicitly update the weights of the network using that minibatch of data.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="mi">1</span> <span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">):</span>
 <span class="mi">2</span>    <span class="sh">"""</span><span class="s">
 3    Set up the part of the computational graph which makes a training step.
 4 
 5    Inputs:
 6    - scores: TensorFlow Tensor of shape (N, C) giving classification scores for
 7      the model.
 8    - y: TensorFlow Tensor of shape (N,) giving ground-truth labels for scores;
 9      y[i] == c means that c is the correct class for scores[i].
10     - params: List of TensorFlow Tensors giving the weights of the model
11     - learning_rate: Python scalar giving the learning rate to use for gradient
12       descent step.
13       
14     Returns:
15     - loss: A TensorFlow Tensor of shape () (scalar) giving the loss for this
16       batch of data; evaluating the loss also performs a gradient descent step
17       on params (see above).
18     </span><span class="sh">"""</span>
<span class="mi">19</span>     <span class="c1"># First compute the loss; the first line gives losses for each example in
</span><span class="mi">20</span>     <span class="c1"># the minibatch, and the second averages the losses acros the batch
</span><span class="mi">21</span>     <span class="n">losses</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nf">sparse_softmax_cross_entropy_with_logits</span><span class="p">(</span><span class="n">labels</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">logits</span><span class="o">=</span><span class="n">scores</span><span class="p">)</span>
<span class="mi">22</span>     <span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">reduce_mean</span><span class="p">(</span><span class="n">losses</span><span class="p">)</span>
<span class="mi">23</span> 
<span class="mi">24</span>     <span class="c1"># Compute the gradient of the loss with respect to each parameter of the the
</span><span class="mi">25</span>     <span class="c1"># network. This is a very magical function call: TensorFlow internally
</span><span class="mi">26</span>     <span class="c1"># traverses the computational graph starting at loss backward to each element
</span><span class="mi">27</span>     <span class="c1"># of params, and uses backpropagation to figure out how to compute gradients;
</span><span class="mi">28</span>     <span class="c1"># it then adds new operations to the computational graph which compute the
</span><span class="mi">29</span>     <span class="c1"># requested gradients, and returns a list of TensorFlow Tensors that will
</span><span class="mi">30</span>     <span class="c1"># contain the requested gradients when evaluated.
</span><span class="mi">31</span>     <span class="n">grad_params</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">gradients</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
<span class="mi">32</span>     
<span class="mi">33</span>     <span class="c1"># Make a gradient descent step on all of the model parameters.
</span><span class="mi">34</span>     <span class="n">new_weights</span> <span class="o">=</span> <span class="p">[]</span>   
<span class="mi">35</span>     <span class="k">for</span> <span class="n">w</span><span class="p">,</span> <span class="n">grad_w</span> <span class="ow">in</span> <span class="nf">zip</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">grad_params</span><span class="p">):</span>
<span class="mi">36</span>         <span class="n">new_w</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">assign_sub</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">grad_w</span><span class="p">)</span>
<span class="mi">37</span>         <span class="n">new_weights</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">new_w</span><span class="p">)</span>
<span class="mi">38</span> 
<span class="mi">39</span>     <span class="c1"># Insert a control dependency so that evaluting the loss causes a weight
</span><span class="mi">40</span>     <span class="c1"># update to happen; see the discussion above.
</span><span class="mi">41</span>     <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="nf">control_dependencies</span><span class="p">(</span><span class="n">new_weights</span><span class="p">):</span>
<span class="mi">42</span>         <span class="k">return</span> <span class="n">tf</span><span class="p">.</span><span class="nf">identity</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
</code></pre></div></div>
<p>you need to be familiar with the function tf.nn.sparse_softmax_cross_entropy_with_logits <strong>Tensorflow : Trainning Loop</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="mi">1</span> <span class="k">def</span> <span class="nf">train_part2</span><span class="p">(</span><span class="n">model_fn</span><span class="p">,</span> <span class="n">init_fn</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">):</span>
 <span class="mi">2</span>    <span class="sh">"""</span><span class="s">
 3    Train a model on CIFAR-10.
 4    
 5    Inputs:
 6    - model_fn: A Python function that performs the forward pass of the model
 7      using TensorFlow; it should have the following signature:
 8      scores = model_fn(x, params) where x is a TensorFlow Tensor giving a
 9      minibatch of image data, params is a list of TensorFlow Tensors holding
10       the model weights, and scores is a TensorFlow Tensor of shape (N, C)
11       giving scores for all elements of x.
12     - init_fn: A Python function that initializes the parameters of the model.
13       It should have the signature params = init_fn() where params is a list
14       of TensorFlow Tensors holding the (randomly initialized) weights of the
15       model.
16     - learning_rate: Python float giving the learning rate to use for SGD.
17     </span><span class="sh">"""</span>
<span class="mi">18</span>     <span class="c1"># First clear the default graph
</span><span class="mi">19</span>     <span class="n">tf</span><span class="p">.</span><span class="nf">reset_default_graph</span><span class="p">()</span>
<span class="mi">20</span>     <span class="n">is_training</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="nb">bool</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="sh">'</span><span class="s">is_training</span><span class="sh">'</span><span class="p">)</span>
<span class="mi">21</span>     <span class="c1"># Set up the computational graph for performing forward and backward passes,
</span><span class="mi">22</span>     <span class="c1"># and weight updates.
</span><span class="mi">23</span>     <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="nf">device</span><span class="p">(</span><span class="n">device</span><span class="p">):</span>
<span class="mi">24</span>         <span class="c1"># Set up placeholders for the data and labels
</span><span class="mi">25</span>         <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="mi">26</span>         <span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">int32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">])</span>
<span class="mi">27</span>         <span class="n">params</span> <span class="o">=</span> <span class="nf">init_fn</span><span class="p">()</span>           <span class="c1"># Initialize the model parameters
</span><span class="mi">28</span>         <span class="n">scores</span> <span class="o">=</span> <span class="nf">model_fn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span> <span class="c1"># Forward pass of the model
</span><span class="mi">29</span>         <span class="n">loss</span> <span class="o">=</span> <span class="nf">training_step</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">)</span>
<span class="mi">30</span> 
<span class="mi">31</span>     <span class="c1"># Now we actually run the graph many times using the training data
</span><span class="mi">32</span>     <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="nc">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
<span class="mi">33</span>         <span class="c1"># Initialize variables that will live in the graph
</span><span class="mi">34</span>         <span class="n">sess</span><span class="p">.</span><span class="nf">run</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="nf">global_variables_initializer</span><span class="p">())</span>
<span class="mi">35</span>         <span class="k">for</span> <span class="n">t</span><span class="p">,</span> <span class="p">(</span><span class="n">x_np</span><span class="p">,</span> <span class="n">y_np</span><span class="p">)</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">train_dset</span><span class="p">):</span>
<span class="mi">36</span>             <span class="c1"># Run the graph on a batch of training data; recall that asking
</span><span class="mi">37</span>             <span class="c1"># TensorFlow to evaluate loss will cause an SGD step to happen.
</span><span class="mi">38</span>             <span class="n">feed_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">x</span><span class="p">:</span> <span class="n">x_np</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">y_np</span><span class="p">}</span>
<span class="mi">39</span>             <span class="n">loss_np</span> <span class="o">=</span> <span class="n">sess</span><span class="p">.</span><span class="nf">run</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="n">feed_dict</span><span class="p">)</span>
<span class="mi">40</span>             
<span class="mi">41</span>             <span class="c1"># Periodically print the loss and check accuracy on the val set
</span><span class="mi">42</span>             <span class="k">if</span> <span class="n">t</span> <span class="o">%</span> <span class="n">print_every</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
<span class="mi">43</span>                 <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Iteration %d, loss = %.4f</span><span class="sh">'</span> <span class="o">%</span> <span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">loss_np</span><span class="p">))</span>
<span class="mi">44</span>                 <span class="nf">check_accuracy</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">val_dset</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">is_training</span><span class="p">)</span>
</code></pre></div></div>
<p><strong>Barebones TensorFlow: Check Accuracy</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="mi">1</span> <span class="k">def</span> <span class="nf">check_accuracy</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">dset</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">is_training</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
 <span class="mi">2</span>    <span class="sh">"""</span><span class="s">
 3    Check accuracy on a classification model.
 4    
 5    Inputs:
 6    - sess: A TensorFlow Session that will be used to run the graph
 7    - dset: A Dataset object on which to check accuracy
 8    - x: A TensorFlow placeholder Tensor where input images should be fed
 9    - scores: A TensorFlow Tensor representing the scores output from the
10       model; this is the Tensor we will ask TensorFlow to evaluate.
11       
12     Returns: Nothing, but prints the accuracy of the model
13     </span><span class="sh">"""</span>
<span class="mi">14</span>     <span class="n">num_correct</span><span class="p">,</span> <span class="n">num_samples</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>
<span class="mi">15</span>     <span class="k">for</span> <span class="n">x_batch</span><span class="p">,</span> <span class="n">y_batch</span> <span class="ow">in</span> <span class="n">dset</span><span class="p">:</span>
<span class="mi">16</span>         <span class="n">feed_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">x</span><span class="p">:</span> <span class="n">x_batch</span><span class="p">,</span> <span class="n">is_training</span><span class="p">:</span> <span class="mi">0</span><span class="p">}</span>
<span class="mi">17</span>         <span class="n">scores_np</span> <span class="o">=</span> <span class="n">sess</span><span class="p">.</span><span class="nf">run</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="n">feed_dict</span><span class="p">)</span>
<span class="mi">18</span>         <span class="n">y_pred</span> <span class="o">=</span> <span class="n">scores_np</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="mi">19</span>         <span class="n">num_samples</span> <span class="o">+=</span> <span class="n">x_batch</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="mi">20</span>         <span class="n">num_correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">y_pred</span> <span class="o">==</span> <span class="n">y_batch</span><span class="p">).</span><span class="nf">sum</span><span class="p">()</span>
<span class="mi">21</span>     <span class="n">acc</span> <span class="o">=</span> <span class="nf">float</span><span class="p">(</span><span class="n">num_correct</span><span class="p">)</span> <span class="o">/</span> <span class="n">num_samples</span>
<span class="mi">22</span>     <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Got %d / %d correct (%.2f%%)</span><span class="sh">'</span> <span class="o">%</span> <span class="p">(</span><span class="n">num_correct</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">,</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">acc</span><span class="p">))</span>
</code></pre></div></div>
<p>I will omit the initilization part because it’s similar to the pytorch part. To sum up, the process of training the passing values are the same as they do in the pytorch, but in the tensorflow we need to use placeholder and sess.run to make it work,and tbh, tensorflow it’s a little bit difficult to get started at the very begining comparing to pytorch.</p>

<h3 id="keras-model-api">Keras Model API</h3>

<p>Implementing a neural network using the low-level TensorFlow API is a good way to understand how TensorFlow works, but it’s a little inconvenient - we had to manually keep track of all Tensors holding learnable parameters, and we had to use a control dependency to implement the gradient descent update step. This was fine for a small network, but could quickly become unweildy for a large complex model.</p>

<p>Fortunately TensorFlow provides higher-level packages such as <code class="language-plaintext highlighter-rouge">tf.keras</code> and <code class="language-plaintext highlighter-rouge">tf.layers</code> which make it easy to build models out of modular, object-oriented layers; <code class="language-plaintext highlighter-rouge">tf.train</code> allows you to easily train these models using a variety of different optimization algorithms.</p>

<h3 id="keras-model-api-three-layer-convnet">Keras Model API: Three-Layer ConvNet</h3>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="mf">1.</span> <span class="n">Convolutional</span> <span class="n">layer</span> <span class="k">with</span> <span class="mi">5</span> <span class="n">x</span> <span class="mi">5</span> <span class="n">kernels</span><span class="p">,</span> <span class="k">with</span> <span class="n">zero</span><span class="o">-</span><span class="n">padding</span> <span class="n">of</span> <span class="mi">2</span>
<span class="mf">2.</span> <span class="n">ReLU</span> <span class="n">nonlinearity</span>
<span class="mf">3.</span> <span class="n">Convolutional</span> <span class="n">layer</span> <span class="k">with</span> <span class="mi">3</span> <span class="n">x</span> <span class="mi">3</span> <span class="n">kernels</span><span class="p">,</span> <span class="k">with</span> <span class="n">zero</span><span class="o">-</span><span class="n">padding</span> <span class="n">of</span> <span class="mi">1</span>
<span class="mf">4.</span> <span class="n">ReLU</span> <span class="n">nonlinearity</span>
<span class="mf">5.</span> <span class="n">Fully</span><span class="o">-</span><span class="n">connected</span> <span class="n">layer</span> <span class="n">to</span> <span class="n">give</span> <span class="k">class</span> <span class="nc">scores</span>

 <span class="mi">1</span> <span class="k">class</span> <span class="nc">ThreeLayerConvNet</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">Model</span><span class="p">):</span>
 <span class="mi">2</span>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">channel_1</span><span class="p">,</span> <span class="n">channel_2</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">):</span>
 <span class="mi">3</span>        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
 <span class="mi">4</span>        <span class="c1">########################################################################
</span> <span class="mi">5</span>        <span class="c1"># TODO: Implement the __init__ method for a three-layer ConvNet. You   #
</span> <span class="mi">6</span>        <span class="c1"># should instantiate layer objects to be used in the forward pass.     #
</span> <span class="mi">7</span>        <span class="c1">########################################################################
</span> <span class="mi">8</span>        <span class="n">initializer</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">variance_scaling_initializer</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="mf">2.0</span><span class="p">)</span>
 <span class="mi">9</span>        <span class="n">self</span><span class="p">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Conv2D</span><span class="p">(</span><span class="n">channel_1</span><span class="p">,[</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">],</span><span class="n">strides</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
<span class="mi">10</span>                                 <span class="n">padding</span><span class="o">=</span><span class="sh">"</span><span class="s">valid</span><span class="sh">"</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">relu</span><span class="p">,</span>
<span class="mi">11</span>                                 <span class="n">kernel_initializer</span> <span class="o">=</span> <span class="n">initializer</span><span class="p">)</span>
<span class="mi">12</span>         <span class="n">self</span><span class="p">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Conv2D</span><span class="p">(</span><span class="n">channel_2</span><span class="p">,[</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span><span class="n">strides</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
<span class="mi">13</span>                                 <span class="n">padding</span><span class="o">=</span><span class="sh">"</span><span class="s">valid</span><span class="sh">"</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">relu</span><span class="p">,</span>
<span class="mi">14</span>                                 <span class="n">kernel_initializer</span> <span class="o">=</span> <span class="n">initializer</span><span class="p">)</span>
<span class="mi">15</span>         <span class="n">self</span><span class="p">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="n">num_classes</span><span class="p">,</span><span class="n">kernel_initializer</span><span class="o">=</span><span class="n">initializer</span><span class="p">)</span>
<span class="mi">16</span>         <span class="c1">#pass
</span><span class="mi">17</span>         <span class="c1">########################################################################
</span><span class="mi">18</span>         <span class="c1">#                           END OF YOUR CODE                           #
</span><span class="mi">19</span>         <span class="c1">########################################################################
</span></code></pre></div></div>
<p>Training Loop:</p>

<p>We need to implement a slightly different training loop when using the <code class="language-plaintext highlighter-rouge">tf.keras.Model</code> API. Instead of computing gradients and updating the weights of the model manually, we use an <code class="language-plaintext highlighter-rouge">Optimizer</code> object from the <code class="language-plaintext highlighter-rouge">tf.train</code> package which takes care of these details for us. You can read more about</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="mi">1</span> <span class="k">def</span> <span class="nf">train_part34</span><span class="p">(</span><span class="n">model_init_fn</span><span class="p">,</span> <span class="n">optimizer_init_fn</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
 <span class="mi">2</span>    <span class="sh">"""</span><span class="s">
 3    Simple training loop for use with models defined using tf.keras. It trains
 4    a model for one epoch on the CIFAR-10 training set and periodically checks
 5    accuracy on the CIFAR-10 validation set.
 6    
 7    Inputs:
 8    - model_init_fn: A function that takes no parameters; when called it
 9      constructs the model we want to train: model = model_init_fn()
10     - optimizer_init_fn: A function which takes no parameters; when called it
11       constructs the Optimizer object we will use to optimize the model:
12       optimizer = optimizer_init_fn()
13     - num_epochs: The number of epochs to train for
14     
15     Returns: Nothing, but prints progress during trainingn
16     </span><span class="sh">"""</span>
<span class="mi">17</span>     <span class="n">tf</span><span class="p">.</span><span class="nf">reset_default_graph</span><span class="p">()</span>    
<span class="mi">18</span>     <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="nf">device</span><span class="p">(</span><span class="n">device</span><span class="p">):</span>
<span class="mi">19</span>         <span class="c1"># Construct the computational graph we will use to train the model. We
</span><span class="mi">20</span>         <span class="c1"># use the model_init_fn to construct the model, declare placeholders for
</span><span class="mi">21</span>         <span class="c1"># the data and labels
</span><span class="mi">22</span>         <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="mi">23</span>         <span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">int32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">])</span>
<span class="mi">24</span>         
<span class="mi">25</span>         <span class="c1"># We need a place holder to explicitly specify if the model is in the training
</span><span class="mi">26</span>         <span class="c1"># phase or not. This is because a number of layers behaves differently in
</span><span class="mi">27</span>         <span class="c1"># training and in testing, e.g., dropout and batch normalization.
</span><span class="mi">28</span>         <span class="c1"># We pass this variable to the computation graph through feed_dict as shown below.
</span><span class="mi">29</span>         <span class="n">is_training</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="nb">bool</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="sh">'</span><span class="s">is_training</span><span class="sh">'</span><span class="p">)</span>
<span class="mi">30</span>         
<span class="mi">31</span>         <span class="c1"># Use the model function to build the forward pass.
</span><span class="mi">32</span>         <span class="n">scores</span> <span class="o">=</span> <span class="nf">model_init_fn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">is_training</span><span class="p">)</span>
<span class="mi">33</span> 
<span class="mi">34</span>         <span class="c1"># Compute the loss like we did in Part II
</span><span class="mi">35</span>         <span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nf">sparse_softmax_cross_entropy_with_logits</span><span class="p">(</span><span class="n">labels</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">logits</span><span class="o">=</span><span class="n">scores</span><span class="p">)</span>
<span class="mi">36</span>         <span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">reduce_mean</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
<span class="mi">37</span> 
<span class="mi">38</span>         <span class="c1"># Use the optimizer_fn to construct an Optimizer, then use the optimizer
</span><span class="mi">39</span>         <span class="c1"># to set up the training step. Asking TensorFlow to evaluate the
</span><span class="mi">40</span>         <span class="c1"># train_op returned by optimizer.minimize(loss) will cause us to make a
</span><span class="mi">41</span>         <span class="c1"># single update step using the current minibatch of data.
</span><span class="mi">42</span>         
<span class="mi">43</span>         <span class="c1"># Note that we use tf.control_dependencies to force the model to run
</span><span class="mi">44</span>         <span class="c1"># the tf.GraphKeys.UPDATE_OPS at each training step. tf.GraphKeys.UPDATE_OPS
</span><span class="mi">45</span>         <span class="c1"># holds the operators that update the states of the network.
</span><span class="mi">46</span>         <span class="c1"># For example, the tf.layers.batch_normalization function adds the running mean
</span><span class="mi">47</span>         <span class="c1"># and variance update operators to tf.GraphKeys.UPDATE_OPS.
</span><span class="mi">48</span>         <span class="n">optimizer</span> <span class="o">=</span> <span class="nf">optimizer_init_fn</span><span class="p">()</span>
<span class="mi">49</span>         <span class="n">update_ops</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">get_collection</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">GraphKeys</span><span class="p">.</span><span class="n">UPDATE_OPS</span><span class="p">)</span>
<span class="mi">50</span>         <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="nf">control_dependencies</span><span class="p">(</span><span class="n">update_ops</span><span class="p">):</span>
<span class="mi">51</span>             <span class="n">train_op</span> <span class="o">=</span> <span class="n">optimizer</span><span class="p">.</span><span class="nf">minimize</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
<span class="mi">52</span> 
<span class="mi">53</span>     <span class="c1"># Now we can run the computational graph many times to train the model.
</span><span class="mi">54</span>     <span class="c1"># When we call sess.run we ask it to evaluate train_op, which causes the
</span><span class="mi">55</span>     <span class="c1"># model to update.
</span><span class="mi">56</span>     <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="nc">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
<span class="mi">57</span>         <span class="n">sess</span><span class="p">.</span><span class="nf">run</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="nf">global_variables_initializer</span><span class="p">())</span>
<span class="mi">58</span>         <span class="n">t</span> <span class="o">=</span> <span class="mi">0</span>
<span class="mi">59</span>         <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
<span class="mi">60</span>             <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Starting epoch %d</span><span class="sh">'</span> <span class="o">%</span> <span class="n">epoch</span><span class="p">)</span>
<span class="mi">61</span>             <span class="k">for</span> <span class="n">x_np</span><span class="p">,</span> <span class="n">y_np</span> <span class="ow">in</span> <span class="n">train_dset</span><span class="p">:</span>
<span class="mi">62</span>                 <span class="n">feed_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">x</span><span class="p">:</span> <span class="n">x_np</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">y_np</span><span class="p">,</span> <span class="n">is_training</span><span class="p">:</span><span class="mi">1</span><span class="p">}</span>
<span class="mi">63</span>                 <span class="n">loss_np</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">sess</span><span class="p">.</span><span class="nf">run</span><span class="p">([</span><span class="n">loss</span><span class="p">,</span> <span class="n">train_op</span><span class="p">],</span> <span class="n">feed_dict</span><span class="o">=</span><span class="n">feed_dict</span><span class="p">)</span>
<span class="mi">64</span>                 <span class="k">if</span> <span class="n">t</span> <span class="o">%</span> <span class="n">print_every</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
<span class="mi">65</span>                     <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Iteration %d, loss = %.4f</span><span class="sh">'</span> <span class="o">%</span> <span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">loss_np</span><span class="p">))</span>
<span class="mi">66</span>                     <span class="nf">check_accuracy</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">val_dset</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">is_training</span><span class="o">=</span><span class="n">is_training</span><span class="p">)</span>
<span class="mi">67</span>                     <span class="nf">print</span><span class="p">()</span>
<span class="mi">68</span>                 <span class="n">t</span> <span class="o">+=</span> <span class="mi">1</span>
</code></pre></div></div>
<p>Finally :</p>

<h3 id="keras-sequential-api">Keras Sequential API</h3>

<p>Here you should use <code class="language-plaintext highlighter-rouge">tf.keras.Sequential</code> to reimplement the same three-layer ConvNet architecture used in Part II and Part III. As a reminder, your model should have the following architecture:</p>

<ol>
  <li>Convolutional layer with 16 5x5 kernels, using zero padding of 2</li>
  <li>ReLU nonlinearity</li>
  <li>Convolutional layer with 32 3x3 kernels, using zero padding of 1</li>
  <li>ReLU nonlinearity</li>
  <li>Fully-connected layer giving class scores</li>
</ol>

<p>You should initialize the weights of the model using a <code class="language-plaintext highlighter-rouge">tf.variance_scaling_initializer</code> as above.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="mi">1</span> <span class="k">def</span> <span class="nf">model_init_fn</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">is_training</span><span class="p">):</span>
 <span class="mi">2</span>    <span class="n">model</span> <span class="o">=</span> <span class="bp">None</span>
 <span class="mi">3</span>    <span class="c1">############################################################################
</span> <span class="mi">4</span>    <span class="c1"># TODO: Construct a three-layer ConvNet using tf.keras.Sequential.         #
</span> <span class="mi">5</span>    <span class="c1">############################################################################
</span> <span class="mi">6</span>    <span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
 <span class="mi">7</span>    <span class="n">channel_1</span><span class="p">,</span> <span class="n">channel_2</span><span class="p">,</span> <span class="n">num_classes</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">10</span>
 <span class="mi">8</span>    <span class="n">initializer</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">variance_scaling_initializer</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="mf">2.0</span><span class="p">)</span>
 <span class="mi">9</span>    <span class="n">layers</span> <span class="o">=</span> <span class="p">[</span>
<span class="mi">10</span>         <span class="c1"># 'Same' padding acts similar to zero padding of 2 for this input
</span><span class="mi">11</span>         <span class="n">tf</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Conv2D</span><span class="p">(</span><span class="n">channel_1</span><span class="p">,[</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">],</span><span class="n">strides</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
<span class="mi">12</span>                                 <span class="n">padding</span><span class="o">=</span><span class="sh">"</span><span class="s">same</span><span class="sh">"</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">relu</span><span class="p">,</span>
<span class="mi">13</span>                                 <span class="n">kernel_initializer</span> <span class="o">=</span> <span class="n">initializer</span><span class="p">,</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span><span class="mi">3</span><span class="p">)),</span>
<span class="mi">14</span>         <span class="n">tf</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Conv2D</span><span class="p">(</span><span class="n">channel_2</span><span class="p">,[</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span><span class="n">strides</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
<span class="mi">15</span>                                 <span class="n">padding</span><span class="o">=</span><span class="sh">"</span><span class="s">same</span><span class="sh">"</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">relu</span><span class="p">,</span>
<span class="mi">16</span>                                 <span class="n">kernel_initializer</span> <span class="o">=</span> <span class="n">initializer</span><span class="p">),</span>
<span class="mi">17</span>         <span class="n">tf</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="n">input_shape</span><span class="p">),</span>
<span class="mi">18</span>         <span class="n">tf</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">initializer</span><span class="p">),</span>
<span class="mi">19</span>     <span class="p">]</span>
<span class="mi">20</span>     <span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">(</span><span class="n">layers</span><span class="p">)</span>
<span class="mi">21</span>     <span class="c1">#pass
</span><span class="mi">22</span>     <span class="c1">############################################################################
</span><span class="mi">23</span>     <span class="c1">#                            END OF YOUR CODE                              #
</span><span class="mi">24</span>     <span class="c1">############################################################################
</span><span class="mi">25</span>     <span class="k">return</span> <span class="nf">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="mi">26</span> 
<span class="mi">27</span> <span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">5e-4</span>
<span class="mi">28</span> <span class="k">def</span> <span class="nf">optimizer_init_fn</span><span class="p">():</span>
<span class="mi">29</span>     <span class="n">optimizer</span> <span class="o">=</span> <span class="bp">None</span>
<span class="mi">30</span>     <span class="c1">############################################################################
</span><span class="mi">31</span>     <span class="c1"># TODO: Complete the implementation of model_fn.                           #
</span><span class="mi">32</span>     <span class="c1">############################################################################
</span><span class="mi">33</span>     <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">train</span><span class="p">.</span><span class="nc">MomentumOptimizer</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="n">use_nesterov</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="mi">34</span> 
<span class="mi">35</span>     <span class="c1">############################################################################
</span><span class="mi">36</span>     <span class="c1">#                           END OF YOUR CODE                               #
</span><span class="mi">37</span>     <span class="c1">############################################################################
</span><span class="mi">38</span>     <span class="k">return</span> <span class="n">optimizer</span>
<span class="mi">39</span> 
<span class="mi">40</span> <span class="nf">train_part34</span><span class="p">(</span><span class="n">model_init_fn</span><span class="p">,</span> <span class="n">optimizer_init_fn</span><span class="p">)</span>
</code></pre></div></div>
<p> </p>

<hr>

<p>To be honest, I personally prefer pytorch because it is more succinct and simple in syntax. In contrast, tensorflow is very grammatically complex and needs to be written repeatedly to write such as sess.run and placeholder to run the whole code. <strong>In tensorflow’s Sequential API, dropout and batchnorm are not available,</strong> but those API is very simple and available in pytorch.</p>

<p>Objectively speaking, the advantage of tensorflow is that TF has the perfect community and documentation which are supported by GOOGLE, which is a great benefit for industrial developers. So in the future, although tensorflow has some shortcomings, I will still use it anyway.</p>

<p>(The following content and introduction are based on the assignment of CS231n)</p>

<p>liangliangzheng</p>

<p>July,31,2018</p>

    </div>
  </article>

  

  

  
    
      

  
    
    <br>
    <hr>
    <br>
    <ul class="list-disc pl-8"></ul>

    <!-- Adds related posts to the end of an article -->
    <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2>
    <p class="mb-2">Here are some more articles you might like to read next:</p>
  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/al-folio/blog/2024/google-gemini-updates-flash-15-gemma-2-and-project-astra/">Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra</a>
  </li>

  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/al-folio/blog/2022/displaying-external-posts-on-your-al-folio-blog/">Displaying External Posts on Your al-folio Blog</a>
  </li>

  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/al-folio/blog/2024/What-is-Mathematics-CH1-Solution/">What is Mathematics: Solution Chapter 1</a>
  </li>

  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/al-folio/blog/2023/small-guide-to-supplements-what-you-need-to-know/">A small guide to supplements: What you need to know</a>
  </li>

  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/al-folio/blog/2022/%E6%B7%B7%E4%B9%B1%E4%B8%8E%E7%A7%A9%E5%BA%8F/">混乱与秩序</a>
  </li>


    
  

  
  
    <div id="giscus_thread" style="max-width: 930px; margin: 0 auto;">
  
    
    <blockquote>
  <h5 id="giscus-comments-misconfigured--please-follow-instructions-at">giscus comments misconfigured &gt; Please follow instructions at</h5>
  <p><a href="http://giscus.app" rel="external nofollow noopener" target="_blank">http://giscus.app</a> and update your giscus configuration. {: .block-danger }</p>
</blockquote>

  
</div>

  
</div>
</div>
          </div>
        
      
    </div>

    <!-- Footer -->
    
  <footer class="fixed-bottom" role="contentinfo">
    <div class="container mt-0">
      © Copyright 2024
      Liangliang
      
      Zheng. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>.

      
      
    </div>
  </footer>



    <!-- JavaScripts -->
    <!-- jQuery -->
<script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
<script src="/al-folio/assets/js/bootstrap.bundle.min.js"></script>
<!-- <script src="/al-folio/assets/js/mdb.min.js"></script> -->
<script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    
  <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script>
  <script defer src="/al-folio/assets/js/masonry.js" type="text/javascript"></script>


    

    

    

    

    

    

    

    

    

  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script>
  <script defer src="/al-folio/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script>


  <!-- Sidebar Table of Contents -->
  <script defer src="/al-folio/assets/js/bootstrap-toc.min.js?c82ff4de8b0955d6ff14f5b05eed7eb6"></script>


<!-- Bootstrap Table -->


<!-- Load Common JS -->
<script src="/al-folio/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script>
<script defer src="/al-folio/assets/js/common.js?06cae41083477f121be8cd9797ad8e2f"></script>
<script defer src="/al-folio/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script>

<!-- Jupyter Open External Links New Tab -->
<script defer src="/al-folio/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script>



    
  <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>


  <script async src="https://badge.dimensions.ai/badge.js"></script>


    
  
    <!-- MathJax -->
    <script type="text/javascript">
      window.MathJax = {
        tex: {
          tags: 'ams',
        },
      };
    </script>
    <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js" integrity="sha256-rjmgmaB99riUNcdlrDtcAiwtLIojSxNyUFdl+Qh+rB4=" crossorigin="anonymous"></script>
    <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script>
  


    

    


    
  <!-- Scrolling Progress Bar -->
  <script type="text/javascript">
    /*
     * This JavaScript code has been adapted from the article
     * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar,
     * published on the website https://css-tricks.com on the 7th of May, 2014.
     * Couple of changes were made to the original code to make it compatible
     * with the `al-foio` theme.
     */
    const progressBar = $('#progress');
    /*
     * We set up the bar after all elements are done loading.
     * In some cases, if the images in the page are larger than the intended
     * size they'll have on the page, they'll be resized via CSS to accomodate
     * the desired size. This mistake, however, breaks the computations as the
     * scroll size is computed as soon as the elements finish loading.
     * To account for this, a minimal delay was introduced before computing the
     * values.
     */
    window.onload = function () {
      setTimeout(progressBarSetup, 50);
    };
    /*
     * We set up the bar according to the browser.
     * If the browser supports the progress element we use that.
     * Otherwise, we resize the bar thru CSS styling
     */
    function progressBarSetup() {
      if ('max' in document.createElement('progress')) {
        initializeProgressElement();
        $(document).on('scroll', function () {
          progressBar.attr({ value: getCurrentScrollPosition() });
        });
        $(window).on('resize', initializeProgressElement);
      } else {
        resizeProgressBar();
        $(document).on('scroll', resizeProgressBar);
        $(window).on('resize', resizeProgressBar);
      }
    }
    /*
     * The vertical scroll position is the same as the number of pixels that
     * are hidden from view above the scrollable area. Thus, a value > 0 is
     * how much the user has scrolled from the top
     */
    function getCurrentScrollPosition() {
      return $(window).scrollTop();
    }

    function initializeProgressElement() {
      let navbarHeight = $('#navbar').outerHeight(true);
      $('body').css({ 'padding-top': navbarHeight });
      $('progress-container').css({ 'padding-top': navbarHeight });
      progressBar.css({ top: navbarHeight });
      progressBar.attr({
        max: getDistanceToScroll(),
        value: getCurrentScrollPosition(),
      });
    }
    /*
     * The offset between the html document height and the browser viewport
     * height will be greater than zero if vertical scroll is possible.
     * This is the distance the user can scroll
     */
    function getDistanceToScroll() {
      return $(document).height() - $(window).height();
    }

    function resizeProgressBar() {
      progressBar.css({ width: getWidthPercentage() + '%' });
    }
    // The scroll ratio equals the percentage to resize the bar
    function getWidthPercentage() {
      return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
    }
  </script>


    

    

    

    
  <script src="/al-folio/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script>
  <script>
    addBackToTop();
  </script>


    
  <script type="module" src="/al-folio/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script>
  <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys>
  <script>
    let searchTheme = determineComputedTheme();
    const ninjaKeys = document.querySelector('ninja-keys');

    if (searchTheme === 'dark') {
      ninjaKeys.classList.add('dark');
    } else {
      ninjaKeys.classList.remove('dark');
    }

    const openSearchModal = () => {
      // collapse navbarNav if expanded on mobile
      const $navbarNav = $('#navbarNav');
      if ($navbarNav.hasClass('show')) {
        $navbarNav.collapse('hide');
      }
      ninjaKeys.open();
    };
  </script>
  <script>
    // get the ninja-keys element
    const ninja = document.querySelector('ninja-keys');

    // add the home and posts menu items
    ninja.data = [{
        id: "nav-about",
        title: "about",
        section: "Navigation",
        handler: () => {
          window.location.href = "/al-folio/";
        },
      },{id: "nav-blog",
              title: "blog",
              description: "",
              section: "Navigation",
              handler: () => {
                window.location.href = "/al-folio/blog/";
              },
            },{id: "nav-repositories",
              title: "repositories",
              description: "",
              section: "Navigation",
              handler: () => {
                window.location.href = "/al-folio/repositories/";
              },
            },{id: "nav-cv",
              title: "CV",
              description: "Personal CV, updated on 15 Jun, 2024",
              section: "Navigation",
              handler: () => {
                window.location.href = "/al-folio/cv/";
              },
            },{id: "dropdown-by-year",
                  title: "by year",
                  description: "",
                  section: "Dropdown",
                  handler: () => {
                    window.location.href = "";
                  },
                },{id: "dropdown-by-category",
                  title: "by category",
                  description: "",
                  section: "Dropdown",
                  handler: () => {
                    window.location.href = "";
                  },
                },{id: "post-google-gemini-updates-flash-1-5-gemma-2-and-project-astra",
          
            // TODO: fix the svg icon position for external posts
            // title: 'Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra <svg width="2rem" height="2rem" top=".5rem" viewbox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',
            title: "Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra",
          
          description: "We’re sharing updates across our Gemini family of models and a glimpse of Project Astra, our vision for the future of AI assistants.",
          section: "Posts",
          handler: () => {
            
              window.open("https://blog.google/technology/ai/google-gemini-update-flash-ai-assistant-io-2024/", "_blank");
            
          },
        },{id: "post-what-is-mathematics-solution-chapter-1",
          
            title: "What is Mathematics: Solution Chapter 1",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2024/What-is-Mathematics-CH1-Solution/";
            
          },
        },{id: "post-a-small-guide-to-supplements-what-you-need-to-know",
          
            title: "A small guide to supplements: What you need to know",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2023/small-guide-to-supplements-what-you-need-to-know/";
            
          },
        },{id: "post-混乱与秩序",
          
            title: "混乱与秩序",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2022/%E6%B7%B7%E4%B9%B1%E4%B8%8E%E7%A7%A9%E5%BA%8F/";
            
          },
        },{id: "post-podcast-notes-huberman-lab-dopomine",
          
            title: "Podcast Notes: Huberman Lab Dopomine",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2022/podcast-notes-huberman-lab-dopomine/";
            
          },
        },{id: "post-displaying-external-posts-on-your-al-folio-blog",
          
            // TODO: fix the svg icon position for external posts
            // title: 'Displaying External Posts on Your al-folio Blog <svg width="2rem" height="2rem" top=".5rem" viewbox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',
            title: "Displaying External Posts on Your al-folio Blog",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.open("https://medium.com/@al-folio/displaying-external-posts-on-your-al-folio-blog-b60a1d241a0a?source=rss-17feae71c3c4------2", "_blank");
            
          },
        },{id: "post-erc-721",
          
            title: "ERC 721",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2022/erc-721/";
            
          },
        },{id: "post-cost-functions-and-its-properties-in-deep-learning-tbc",
          
            title: "Cost Functions and its properties in Deep Learning (TBC)",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2022/cost-functions-and-its-properties-in-deep-learning-tbc/";
            
          },
        },{id: "post-cv-modifying",
          
            title: "CV: Modifying",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2022/cv-modifying/";
            
          },
        },{id: "post-cheatsheet-pandas-dataframe-commonly-used",
          
            title: "Cheatsheet: Pandas, Dataframe, (commonly used)",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2021/cheatsheet-pandas-dataframe-seriescommonly-used/";
            
          },
        },{id: "post-人生何处不滥情",
          
            title: "人生何处不滥情",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2021/%E4%BA%BA%E7%94%9F%E4%BD%95%E5%A4%84%E4%B8%8D%E6%BB%A5%E6%83%85/";
            
          },
        },{id: "post-hash-bang-bin-bash-tbc",
          
            title: "hash bang/bin/bash (tbc)",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2021/hash-bang-bin-bash-tbc/";
            
          },
        },{id: "post-mit-15-s12-blockchain-and-money-note-lec-7-9-tbc",
          
            title: "MIT 15.S12 Blockchain and Money Note (Lec 7~9) tbc",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2021/mit-15-s12-blockchain-and-money-note-lec-79-tbc/";
            
          },
        },{id: "post-mit-15-s12-blockchain-and-money-note-lec-6",
          
            title: "MIT 15.S12 Blockchain and Money Note (Lec 6)",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2021/mit-15-s12-blockchain-and-money-note-lec-6-tbc/";
            
          },
        },{id: "post-mit-15-s12-blockchain-and-money-note-lec-5",
          
            title: "MIT 15.S12 Blockchain and Money Note (Lec 5)",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2021/mit-15-s12-blockchain-and-money-note-lec-5/";
            
          },
        },{id: "post-awk-sed-grep-总结",
          
            title: "awk, sed, grep 总结",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2021/awk-sed-grep-%E6%80%BB%E7%BB%93/";
            
          },
        },{id: "post-mit-15-s12-blockchain-and-money-note-lec-4",
          
            title: "MIT 15.S12 Blockchain and Money Note (Lec 4)",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2021/mit-15-s12-blockchain-and-money-note-lec-4/";
            
          },
        },{id: "post-mit-15-s12-blockchain-and-money-note-lec-3",
          
            title: "MIT 15.S12 Blockchain and Money Note (Lec 3)",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2021/mit-15-s12-blockchain-and-money-note-lec-3/";
            
          },
        },{id: "post-mit-15-s12-blockchain-and-money-note-lec-2",
          
            title: "MIT 15.S12 Blockchain and Money Note (Lec 2)",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2021/mit-15-s12-blockchain-and-money-note-lec-2/";
            
          },
        },{id: "post-mit-15-s12-blockchain-and-money-note-lec-1",
          
            title: "MIT 15.S12 Blockchain and Money Note (Lec 1)",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2021/15-s12-blockchain-and-money-note1/";
            
          },
        },{id: "post-浅尝-39-则-39-止-正则",
          
            title: "浅尝'则'止: 正则",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2021/%E6%B5%85%E5%B0%9D%E5%88%99%E6%AD%A2-%E6%AD%A3%E5%88%99%E4%B8%8E%E5%85%B6%E5%BC%95%E6%93%8E%E5%AE%9E%E7%8E%B0tbc/";
            
          },
        },{id: "post-python巩固整理",
          
            title: "Python巩固整理",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2021/python%E8%BF%9B%E9%98%B6%E5%B7%A9%E5%9B%BA%E6%95%B4%E7%90%86/";
            
          },
        },{id: "post-别虽然但是了-2020过去了",
          
            title: "别虽然但是了，2020过去了．",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2020/%E5%88%AB%E8%99%BD%E7%84%B6%E4%BD%86%E6%98%AF%E4%BA%86-2020%E8%BF%87%E5%8E%BB%E4%BA%86/";
            
          },
        },{id: "post-sql规范与技巧-持续更新",
          
            title: "SQL规范与技巧(持续更新)",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2020/sql%E8%A7%84%E8%8C%83%E4%B8%8E%E6%8A%80%E5%B7%A7/";
            
          },
        },{id: "post-金融读书笔记-3",
          
            title: "金融读书笔记(3)",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2020/%E9%87%91%E8%9E%8D%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B03/";
            
          },
        },{id: "post-金融读书笔记-2",
          
            title: "金融读书笔记(2)",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2020/%E9%87%91%E8%9E%8D%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B02/";
            
          },
        },{id: "post-金融读书笔记-1",
          
            title: "金融读书笔记(1)",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2020/%E9%87%91%E8%9E%8D%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B01/";
            
          },
        },{id: "post-gpt-3是什么",
          
            title: "GPT-3是什么?",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2020/gpt-3/";
            
          },
        },{id: "post-前脑白质切除术",
          
            title: "前脑白质切除术",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2020/%E5%89%8D%E8%84%91%E7%99%BD%E8%B4%A8%E5%88%87%E9%99%A4%E6%9C%AF/";
            
          },
        },{id: "post-personal-github",
          
            title: "Personal Github",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2020/person-github/";
            
          },
        },{id: "post-永别了呀2019",
          
            title: "永别了呀2019",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2019/%E6%B0%B8%E5%88%AB%E4%BA%86%E5%91%802019/";
            
          },
        },{id: "post-emacs-入门-占坑",
          
            title: "Emacs 入门(占坑)",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2019/emacs-%E5%85%A5%E9%97%A8%E5%8D%A0%E5%9D%91/";
            
          },
        },{id: "post-我在备忘录都写些什么",
          
            title: "我在备忘录都写些什么？",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2019/%E6%8C%96%E5%9D%91%E8%BF%87%E5%8E%BB%E7%9A%84%E4%B8%80%E5%B9%B4/";
            
          },
        },{id: "post-adam-vs-radam",
          
            title: "Adam vs. RAdam",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2019/%E5%8D%A0%E5%9D%91-adam-vs-radam/";
            
          },
        },{id: "post-硕士开学第一学期-关于琐事和学习及方法",
          
            title: "硕士开学第一学期——关于琐事和学习及方法",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2018/%E7%A1%95%E5%A3%AB%E5%BC%80%E5%AD%A6%E7%AC%AC%E4%B8%80%E5%AD%A6%E6%9C%9F-%E5%85%B3%E4%BA%8E%E7%90%90%E4%BA%8B%E5%92%8C%E5%AD%A6%E4%B9%A0%E5%8F%8A%E6%96%B9%E6%B3%95/";
            
          },
        },{id: "post-emotion-recognition-based-on-tensorflow",
          
            title: "Emotion Recognition Based on Tensorflow",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2018/emotion-recognition-based-on-tensorflow/";
            
          },
        },{id: "post-python-review-amp-amp-some-simple-algorithms",
          
            title: "Python_review &amp; Some simple algorithms",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2018/python_review-some-simple-algorithms/";
            
          },
        },{id: "post-nlp-word2vec-skip-gram-cs224n-implemented-in-raw-way-and-in-tensorflow",
          
            title: "NLP: Word2Vec Skip-Gram(CS224n) implemented in raw way and in Tensorflow",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2018/nlp-word2vec-skip-gramcs224n/";
            
          },
        },{id: "post-cs231n-assignment3-image-captioning-with-rnns",
          
            title: "CS231n Assignment3_Image Captioning with RNNs",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2018/cs231n-assignment3_image-captioning-with-rnns/";
            
          },
        },{id: "post-pytorch-vs-tensorflow",
          
            title: "Pytorch VS Tensorflow",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2018/pytorch-vs-tensorflow/";
            
          },
        },{id: "post-cs231n-cnn-notes-amp-amp-assignment2",
          
            title: "CS231N_CNN_Notes&amp;Assignment2",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2018/cs231n_cnn_notesassignment2/";
            
          },
        },{id: "post-web-crawler爬top100电影信息",
          
            title: "Web_Crawler爬top100电影信息",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2018/web_crawler%E7%88%ACtop100%E7%94%B5%E5%BD%B1%E4%BF%A1%E6%81%AF/";
            
          },
        },{id: "post-牛客算法直播题目总结day2t1234",
          
            title: "牛客算法直播题目总结Day2T1234",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2017/%E7%89%9B%E5%AE%A2%E7%AE%97%E6%B3%95%E7%9B%B4%E6%92%AD%E9%A2%98%E7%9B%AE%E6%80%BB%E7%BB%93day2t1234/";
            
          },
        },{id: "post-牛客算法直播题目总结day1t234",
          
            title: "牛客算法直播题目总结Day1T234",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2017/%E7%89%9B%E5%AE%A2%E7%AE%97%E6%B3%95%E7%9B%B4%E6%92%AD%E9%A2%98%E7%9B%AE%E6%80%BB%E7%BB%93day1t234%E9%9B%B6%E5%92%8C%E5%8D%9A%E5%BC%88/";
            
          },
        },{id: "post-牛客算法直播题目总结day1t1-零和博弈",
          
            title: "牛客算法直播题目总结Day1T1(零和博弈)",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2017/%E7%89%9B%E5%AE%A2%E7%AE%97%E6%B3%95%E7%9B%B4%E6%92%AD%E9%A2%98%E7%9B%AE%E6%80%BB%E7%BB%93/";
            
          },
        },{id: "post-java学习笔记-六-装饰-观察者模式及监听器",
          
            title: "Java学习笔记(六):装饰、观察者模式及监听器",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2017/java%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%85%AD%E8%A3%85%E9%A5%B0-%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F%E5%8F%8A%E7%9B%91%E5%90%AC%E5%99%A8/";
            
          },
        },{id: "post-java学习笔记-四-filter",
          
            title: "Java学习笔记(四):Filter",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2017/java%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%9B%9Bfilter/";
            
          },
        },{id: "post-java学习笔记-五-文件的上传和下载",
          
            title: "Java学习笔记(五):文件的上传和下载",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2017/java%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%BA%94%E6%96%87%E4%BB%B6%E7%9A%84%E4%B8%8A%E4%BC%A0%E5%92%8C%E4%B8%8B%E8%BD%BD/";
            
          },
        },{id: "post-jdbc学习笔记-三",
          
            title: "JDBC学习笔记(三)",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2017/jdbc%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%B8%89/";
            
          },
        },{id: "post-jdbc学习笔记-二",
          
            title: "JDBC学习笔记(二)",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2017/jdbc%E7%AC%94%E8%AE%B0%E4%BA%8C/";
            
          },
        },{id: "post-jdbc学习笔记-一",
          
            title: "JDBC学习笔记(一)",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2017/jdbc%E7%AC%94%E8%AE%B0%E5%8F%8A%E5%85%B6%E4%BB%96/";
            
          },
        },{id: "post-j2ee-cookie与session知识点回顾",
          
            title: "J2EE_Cookie与Session知识点回顾",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2017/j2ee_cookie%E4%B8%8Esession%E7%9F%A5%E8%AF%86%E7%82%B9%E5%9B%9E%E9%A1%BE/";
            
          },
        },{id: "post-bug-解决-nginx-502-bad-gateway",
          
            title: "Bug：解决 nginx 502 Bad GateWay",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2017/bug-%E8%A7%A3%E5%86%B3-nginx-502-bad-gateway/";
            
          },
        },{id: "post-windows-laravel环境部署",
          
            title: "Windows Laravel环境部署",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2016/windows-laravel%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/";
            
          },
        },{id: "post-git基础记录",
          
            title: "Git基础记录",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2016/git%E5%9F%BA%E7%A1%80%E8%AE%B0%E5%BD%95/";
            
          },
        },{id: "post-算法导论读书笔记-6",
          
            title: "算法导论读书笔记(6)",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2016/%E7%AE%97%E6%B3%95%E5%AF%BC%E8%AE%BA%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B06/";
            
          },
        },{id: "post-qt实现电子词典gui-project",
          
            title: "QT实现电子词典GUI（project）",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2016/qt%E5%AE%9E%E7%8E%B0%E7%94%B5%E5%AD%90%E8%AF%8D%E5%85%B8gui-project/";
            
          },
        },{id: "post-算法导论读书笔记-5",
          
            title: "算法导论读书笔记(5)",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2016/%E7%AE%97%E6%B3%95%E5%AF%BC%E8%AE%BA%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B05/";
            
          },
        },{id: "post-算法导论读书笔记-4",
          
            title: "算法导论读书笔记(4)",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2016/%E7%AE%97%E6%B3%95%E5%AF%BC%E8%AE%BA%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B04/";
            
          },
        },{id: "post-算法导论读书笔记-3",
          
            title: "算法导论读书笔记(3)",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2016/%E7%AE%97%E6%B3%95%E5%AF%BC%E8%AE%BA%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B03/";
            
          },
        },{id: "post-算法导论读书笔记-2",
          
            title: "算法导论读书笔记(2)",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2016/%E7%AE%97%E6%B3%95%E5%AF%BC%E8%AE%BA%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B02/";
            
          },
        },{id: "post-aws免费服务器申请和中继器搭建",
          
            title: "AWS免费服务器申请和中继器搭建",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2016/aws%E5%85%8D%E8%B4%B9%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%94%B3%E8%AF%B7%E5%92%8C%E4%B8%AD%E7%BB%A7%E5%99%A8%E6%90%AD%E5%BB%BA/";
            
          },
        },{id: "post-算法导论读书笔记-1",
          
            title: "算法导论读书笔记（1）",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2016/%E7%AE%97%E6%B3%95%E5%AF%BC%E8%AE%BA%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-1/";
            
          },
        },{id: "post-数据结构之-排序",
          
            title: "数据结构之——排序",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2015/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B-%E6%8E%92%E5%BA%8F/";
            
          },
        },{id: "post-数据结构之-图",
          
            title: "数据结构之——图",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2015/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B-%E5%9B%BE/";
            
          },
        },{id: "post-stl之vector用法",
          
            title: "STL之Vector用法",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2015/stl%E4%B9%8Bvector%E7%94%A8%E6%B3%95/";
            
          },
        },{id: "post-数据结构之-树",
          
            title: "数据结构之——树",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2015/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B-%E6%A0%91/";
            
          },
        },{id: "post-回溯法经典应用-n皇后-amp-amp-迷宫问题",
          
            title: "回溯法经典应用——N皇后&amp;迷宫问题",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2015/%E5%9B%9E%E6%BA%AF%E6%B3%95%E7%BB%8F%E5%85%B8%E5%BA%94%E7%94%A8-n%E7%9A%87%E5%90%8E%E8%BF%B7%E5%AE%AB%E9%97%AE%E9%A2%98/";
            
          },
        },{id: "post-数据结构之-队列",
          
            title: "数据结构之——队列",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2015/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B-%E9%98%9F%E5%88%97/";
            
          },
        },{id: "post-数据结构之-栈",
          
            title: "数据结构之——栈",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2015/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B-%E6%A0%88/";
            
          },
        },{id: "post-大二第一学期计划-备表及其他",
          
            title: "大二第一学期计划/备表及其他",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2015/%E5%A4%A7%E4%BA%8C%E7%AC%AC%E4%B8%80%E5%AD%A6%E6%9C%9F%E8%AE%A1%E5%88%92%E5%A4%87%E8%A1%A8%E5%8F%8A%E5%85%B6%E4%BB%96/";
            
          },
        },{id: "post-利用靓汤beautifulsoup4写一个简易爬虫",
          
            title: "利用靓汤BeautifulSoup4写一个简易爬虫",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2015/%E5%88%A9%E7%94%A8%E9%9D%93%E6%B1%A4beautifulsoup4%E5%86%99%E4%B8%80%E4%B8%AA%E7%AE%80%E6%98%93%E7%88%AC%E8%99%AB/";
            
          },
        },{id: "post-数据结构之-链表",
          
            title: "数据结构之——链表",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2015/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B-%E9%93%BE%E8%A1%A8/";
            
          },
        },{id: "post-数据结构之-向量",
          
            title: "数据结构之——向量",
          
          description: "",
          section: "Posts",
          handler: () => {
            
              window.location.href = "/al-folio/blog/2015/vector/";
            
          },
        },{id: "news-a-simple-inline-announcement-with-markdown-emoji-sparkles-smile",
          title: 'A simple inline announcement with Markdown emoji! <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> <img class="emoji" title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20">',
          description: "",
          section: "News",},{id: "news-a-long-announcement-with-details",
          title: 'A long announcement with details',
          description: "",
          section: "News",handler: () => {
              window.location.href = "/al-folio/news/announcement_2/";
            },},{id: "news-a-simple-inline-announcement",
          title: 'A simple inline announcement.',
          description: "",
          section: "News",},{id: "projects-project-1",
              title: 'project 1',
              description: "with background image",
              section: "Projects",handler: () => {
                  window.location.href = "/al-folio/projects/1_project/";
                },},{id: "projects-project-2",
              title: 'project 2',
              description: "a project with a background image and giscus comments",
              section: "Projects",handler: () => {
                  window.location.href = "/al-folio/projects/2_project/";
                },},{id: "projects-project-3-with-very-long-name",
              title: 'project 3 with very long name',
              description: "a project that redirects to another website",
              section: "Projects",handler: () => {
                  window.location.href = "/al-folio/projects/3_project/";
                },},{id: "projects-project-4",
              title: 'project 4',
              description: "another without an image",
              section: "Projects",handler: () => {
                  window.location.href = "/al-folio/projects/4_project/";
                },},{id: "projects-project-5",
              title: 'project 5',
              description: "a project with a background image",
              section: "Projects",handler: () => {
                  window.location.href = "/al-folio/projects/5_project/";
                },},{id: "projects-project-6",
              title: 'project 6',
              description: "a project with no image",
              section: "Projects",handler: () => {
                  window.location.href = "/al-folio/projects/6_project/";
                },},{id: "projects-project-7",
              title: 'project 7',
              description: "with background image",
              section: "Projects",handler: () => {
                  window.location.href = "/al-folio/projects/7_project/";
                },},{id: "projects-project-8",
              title: 'project 8',
              description: "an other project with a background image and giscus comments",
              section: "Projects",handler: () => {
                  window.location.href = "/al-folio/projects/8_project/";
                },},{id: "projects-project-9",
              title: 'project 9',
              description: "another project with an image 🎉",
              section: "Projects",handler: () => {
                  window.location.href = "/al-folio/projects/9_project/";
                },},{
            id: 'socials-email',
            title: 'Send email',
            section: 'Socials',
            handler: () => {
              window.open("mailto:%7A%68%65%6E%67%6C%69%61%6E%67%6C%69%61%6E%67%31%39%39%37@%67%6D%61%69%6C.%63%6F%6D", "_blank");
            },
          },{
            id: 'socials-rss',
            title: 'RSS Feed',
            section: 'Socials',
            handler: () => {
              window.open("/al-folio/feed.xml", "_blank");
            },
          },{
          id: 'light-theme',
          title: 'Change theme to light',
          description: 'Change the theme of the site to Light',
          section: 'Theme',
          handler: () => {
            setThemeSetting("light");
          },
        },
        {
          id: 'dark-theme',
          title: 'Change theme to dark',
          description: 'Change the theme of the site to Dark',
          section: 'Theme',
          handler: () => {
            setThemeSetting("dark");
          },
        },
        {
          id: 'system-theme',
          title: 'Use system default theme',
          description: 'Change the theme of the site to System Default',
          section: 'Theme',
          handler: () => {
            setThemeSetting("system");
          },
        },];
  </script>


    <script src="/al-folio/assets/js/shortcut-key.js"></script>
  </body>
</html>
