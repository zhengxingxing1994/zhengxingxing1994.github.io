<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Emotion Recognition Based on Tensorflow | Liangliang Zheng </title> <meta name="author" content="Liangliang Zheng"> <meta name="description" content="Welcome to Liangliang's blog, where I share my thoughts and experiences on various topics. "> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link defer href="/assets/css/bootstrap-toc.min.css?6f5af0bb9aab25d79b2448143cbeaa88" rel="stylesheet"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://paranoiarchive.com//blog/2018/emotion-recognition-based-on-tensorflow/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Liangliang</span> Zheng </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">archive </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/archive_by_year">by year</a> <a class="dropdown-item " href="/archive_by_tag">by category</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="row"> <div class="col-sm-3"> <nav id="toc-sidebar" class="sticky-top"></nav> </div> <div class="col-sm-9"> <div class="post"> <header class="post-header"> <h1 class="post-title">Emotion Recognition Based on Tensorflow</h1> <p class="post-meta"> Created in August 24, 2018 </p> <p class="post-tags"> <a href="/blog/2018"> <i class="fa-solid fa-calendar fa-sm"></i> 2018 </a>   ·   <a href="/blog/category/dl-ml-python"> <i class="fa-solid fa-tag fa-sm"></i> dl-ml-python</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>I chose a very simple project to be implemented to finish the whole classs inasmuch as in CS231n course, students were left a project to be done themselves. Well, this could be very simple and basic because I haven’t learnt very detail and implemented all assignments by myself. And this tiny project will be my every first tensorflow &amp; Computer vision project, later on I hope that I can make something creative like advanced style transfer. : )</p> <hr> <ul> <li><strong>Task: Emotion Recognition Based on CNNs</strong></li> </ul> <p>Input a facial image, ouput the emotion( 0 = anger , 1 = disgust , 2 = fear , 3 = happy , 4 = sad , 5 = surprise , 6 = neutral) percentage.</p> <p><strong>For example:</strong></p> <p><img src="https://zhengliangliang.files.wordpress.com/2018/08/fear.jpg" alt="fear.jpg">          <img src="https://zhengliangliang.files.wordpress.com/2018/08/2018-08-24_085215.jpg" alt="2018-08-24_085215.jpg"></p> <ul> <li><strong>Dataset, input shape and label shape</strong></li> </ul> <p>From kaggle , click this <a href="https://www.kaggle.com/c/facial-keypoints-detector/data" rel="external nofollow noopener" target="_blank">link</a></p> <p><strong>Training Input shape</strong>: 3761 grayscale images of 48 * 48 pixels (3761, 48, 48, 1) <strong>Training Label shape</strong>: 3761 class images, seven elements label(mentioned above). <strong>Test Set</strong>:(1312, 48, 48, 1) <strong>Single Image shape</strong>:(48, 48, 1) (The following test img will be resize to 48*48) <strong>label set</strong> = [0. 0. 1. 0. 0. 0. 0.]  (FEAR)</p> <p><img src="https://zhengliangliang.files.wordpress.com/2018/08/figure_1.png" alt="Figure_1.png"></p> <ul> <li><strong>CNN architecture</strong></li> </ul> <p><strong>conv layer</strong><img src="https://zhengliangliang.files.wordpress.com/2018/08/2018-08-24_090035.jpg" alt="2018-08-24_090035.jpg"></p> <p>Original x_image size (48,48,1), through a CNN layer with filter (5, 5, 32) stride = 1, padding = same, then h_conv1 will be (48, 48, 32), then passed to max pooling 2*2, stride = 2 and the shape will be shrunk to(24, 24, 32), then another cnn with filter (3, 3, 64), then again, the max poling, the resulting images are downsampled to 12 * 12 pixels</p> <p><strong>fully connected layer</strong></p> <p><img src="https://zhengliangliang.files.wordpress.com/2018/08/2018-08-24_090833.jpg" alt="2018-08-24_090833.jpg"></p> <p>The (12, 12, 64) will be flatten and passed through 2 fc layers, the final label will be 7 labels.</p> <hr> <ul> <li><strong>Coding part</strong></li> </ul> <p>We set the paths for storing the dataset on the computer, and the network parameters with the following code:(you can simply ignore it if you don’t need it)</p> <p>1 FLAGS = tf.flags.FLAGS 2 tf.flags.DEFINE_string(“data_dir”, “EmotionDetector/”, “Path to data files”) 3 tf.flags.DEFINE_string(“logs_dir”, “logs/EmotionDetector_logs/”, “Path to where log files are to be saved”) 4 tf.flags.DEFINE_string(“mode”, “train”, “mode: train (Default)/ test”)</p> <p>Some constants:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> 1 BATCH_SIZE = 128
 2 LEARNING_RATE = 1e-3
 3 MAX_ITERATIONS = 1001
 4 REGULARIZATION = 1e-2
 5 IMAGE_SIZE = 48
 6 NUM_LABELS = 7
 7 VALIDATION_PERCENT = 0.1
</code></pre></div></div> <p>First of al, define weights and biases’ shape using dict. Pay attention to the shape of weights and biases.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> 1 weights = {
 2    'wc1': weight_variable([5, 5, 1, 32], name="We_conv1"),
 3    'wc2': weight_variable([3, 3, 32, 64],name="We_conv2"),
 4    'wf1': weight_variable([(IMAGE_SIZE // 4) * (IMAGE_SIZE // 4) * 64, 256],name="W_fc1"),
 5    'wf2': weight_variable([256, NUM_LABELS], name="W_fc2")
 6 }
 7 
 8 biases = {
 9    'bc1': bias_variable([32], name="b_conv1"),
10     'bc2': bias_variable([64], name="b_conv2"),
11     'bf1': bias_variable([256], name="b_fc1"),
12     'bf2': bias_variable([NUM_LABELS], name="b_fc2")
13 }
</code></pre></div></div> <p>And the <strong>weight_variable</strong> above is a function for randomly initialization.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> 1 def weight_variable(shape, stddev=0.02, name=None):
 2    initial = tf.truncated_normal(shape, stddev=stddev)
 3    if name is None:
 4        return tf.Variable(initial)
 5    else:
 6        return tf.get_variable(name, initializer=initial)
</code></pre></div></div> <p>in tensorflow, we have a truncated_normal, and all you have to do is pass the shape and standard deviation, in this case, we set stddev to 0.02.</p> <p>Then the rest we need to think about is the calculation of loss, normally in tensorflow we use softmax cross entropy with logits for every loss and tf.reduce_mean for all of the losses, in this project, we also add the regularization part to prevent overfitting.</p> <p>1 def loss(pred, label): 2 cross_entropy_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=label)) 3 tf.summary.scalar(‘Entropy’, cross_entropy_loss) 4 reg_losses = tf.add_n(tf.get_collection(“losses”)) 5 tf.summary.scalar(‘Reg_loss’, reg_losses) 6 return cross_entropy_loss + REGULARIZATION * reg_losses</p> <p>In this loss function, we add tf.summary.scalar for tensorboard, you can simply ignore it if you don’t want to see the graph part, we get the reg_losses from add_n and get_collection, then times the REGULARIZATION constant for the final summation.</p> <p>AFTER defining the loss function, we need a optimizer, in this case, we use AdamOptimizer which you can find on tensorflow documentation.</p> <p>1 def train(loss, step): 2 return tf.train.AdamOptimizer(LEARNING_RATE).minimize(loss, global_step=step)</p> <p>Then comes the most important part, cnn emotion, implemented the architecture we’ve seen above:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="mi">1</span> <span class="k">def</span> <span class="nf">emotion_cnn</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
 <span class="mi">2</span>    <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="nf">name_scope</span><span class="p">(</span><span class="sh">"</span><span class="s">conv1</span><span class="sh">"</span><span class="p">)</span> <span class="k">as</span> <span class="n">scope</span><span class="p">:</span>
 <span class="mi">3</span>        <span class="c1">#W_conv1 = weight_variable([5, 5, 1, 32])
</span> <span class="mi">4</span>        <span class="c1">#b_conv1 = bias_variable([32])
</span> <span class="mi">5</span>        <span class="n">tf</span><span class="p">.</span><span class="n">summary</span><span class="p">.</span><span class="nf">histogram</span><span class="p">(</span><span class="sh">"</span><span class="s">We_conv1</span><span class="sh">"</span><span class="p">,</span> <span class="n">weights</span><span class="p">[</span><span class="sh">'</span><span class="s">wc1</span><span class="sh">'</span><span class="p">])</span>
 <span class="mi">6</span>        <span class="n">tf</span><span class="p">.</span><span class="n">summary</span><span class="p">.</span><span class="nf">histogram</span><span class="p">(</span><span class="sh">"</span><span class="s">b_conv1</span><span class="sh">"</span><span class="p">,</span> <span class="n">biases</span><span class="p">[</span><span class="sh">'</span><span class="s">bc1</span><span class="sh">'</span><span class="p">])</span>
 <span class="mi">7</span>        <span class="n">conv_1</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nf">conv2d</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">weights</span><span class="p">[</span><span class="sh">'</span><span class="s">wc1</span><span class="sh">'</span><span class="p">],</span>
 <span class="mi">8</span>                              <span class="n">strides</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="sh">"</span><span class="s">SAME</span><span class="sh">"</span><span class="p">)</span>
 <span class="mi">9</span>        <span class="n">h_conv1</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nf">bias_add</span><span class="p">(</span><span class="n">conv_1</span><span class="p">,</span> <span class="n">biases</span><span class="p">[</span><span class="sh">'</span><span class="s">bc1</span><span class="sh">'</span><span class="p">])</span>
<span class="mi">10</span>         <span class="c1">#h_conv1 = conv2d_basic(dataset, W_conv1, b_conv1)
</span><span class="mi">11</span>         <span class="n">h_1</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nf">relu</span><span class="p">(</span><span class="n">h_conv1</span><span class="p">)</span>
<span class="mi">12</span>         <span class="n">h_pool1</span> <span class="o">=</span> <span class="nf">max_pool_2x2</span><span class="p">(</span><span class="n">h_1</span><span class="p">)</span>
<span class="mi">13</span>         <span class="nf">add_to_regularization_loss</span><span class="p">(</span><span class="n">weights</span><span class="p">[</span><span class="sh">'</span><span class="s">wc1</span><span class="sh">'</span><span class="p">],</span> <span class="n">biases</span><span class="p">[</span><span class="sh">'</span><span class="s">bc1</span><span class="sh">'</span><span class="p">])</span>
<span class="mi">14</span> 
<span class="mi">15</span>     <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="nf">name_scope</span><span class="p">(</span><span class="sh">"</span><span class="s">conv2</span><span class="sh">"</span><span class="p">)</span> <span class="k">as</span> <span class="n">scope</span><span class="p">:</span>
<span class="mi">16</span>         <span class="c1">#W_conv2 = weight_variable([3, 3, 32, 64])
</span><span class="mi">17</span>         <span class="c1">#b_conv2 = bias_variable([64])
</span><span class="mi">18</span>         <span class="n">tf</span><span class="p">.</span><span class="n">summary</span><span class="p">.</span><span class="nf">histogram</span><span class="p">(</span><span class="sh">"</span><span class="s">We_conv2</span><span class="sh">"</span><span class="p">,</span> <span class="n">weights</span><span class="p">[</span><span class="sh">'</span><span class="s">wc2</span><span class="sh">'</span><span class="p">])</span>
<span class="mi">19</span>         <span class="n">tf</span><span class="p">.</span><span class="n">summary</span><span class="p">.</span><span class="nf">histogram</span><span class="p">(</span><span class="sh">"</span><span class="s">b_conv2</span><span class="sh">"</span><span class="p">,</span> <span class="n">biases</span><span class="p">[</span><span class="sh">'</span><span class="s">bc2</span><span class="sh">'</span><span class="p">])</span>
<span class="mi">20</span>         <span class="n">conv_2</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nf">conv2d</span><span class="p">(</span><span class="n">h_pool1</span><span class="p">,</span> <span class="n">weights</span><span class="p">[</span><span class="sh">'</span><span class="s">wc2</span><span class="sh">'</span><span class="p">],</span> <span class="n">strides</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="sh">"</span><span class="s">SAME</span><span class="sh">"</span><span class="p">)</span>
<span class="mi">21</span>         <span class="n">h_conv2</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nf">bias_add</span><span class="p">(</span><span class="n">conv_2</span><span class="p">,</span> <span class="n">biases</span><span class="p">[</span><span class="sh">'</span><span class="s">bc2</span><span class="sh">'</span><span class="p">])</span>
<span class="mi">22</span>         <span class="c1">#h_conv2 = conv2d_basic(h_pool1, weights['wc2'], biases['bc2'])
</span><span class="mi">23</span>         <span class="n">h_2</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nf">relu</span><span class="p">(</span><span class="n">h_conv2</span><span class="p">)</span>
<span class="mi">24</span>         <span class="n">h_pool2</span> <span class="o">=</span> <span class="nf">max_pool_2x2</span><span class="p">(</span><span class="n">h_2</span><span class="p">)</span>
<span class="mi">25</span>         <span class="nf">add_to_regularization_loss</span><span class="p">(</span><span class="n">weights</span><span class="p">[</span><span class="sh">'</span><span class="s">wc2</span><span class="sh">'</span><span class="p">],</span> <span class="n">biases</span><span class="p">[</span><span class="sh">'</span><span class="s">bc2</span><span class="sh">'</span><span class="p">])</span>
<span class="mi">26</span> 
<span class="mi">27</span>     <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="nf">name_scope</span><span class="p">(</span><span class="sh">"</span><span class="s">fc_1</span><span class="sh">"</span><span class="p">)</span> <span class="k">as</span> <span class="n">scope</span><span class="p">:</span>
<span class="mi">28</span>         <span class="n">prob</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="mi">29</span>         <span class="n">image_size</span> <span class="o">=</span> <span class="n">IMAGE_SIZE</span> <span class="o">//</span> <span class="mi">4</span>
<span class="mi">30</span>         <span class="n">h_flat</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="n">h_pool2</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">image_size</span> <span class="o">*</span> <span class="n">image_size</span> <span class="o">*</span> <span class="mi">64</span><span class="p">])</span>
<span class="mi">31</span>         <span class="c1">#W_fc1 = weight_variable([image_size * image_size * 64, 256])
</span><span class="mi">32</span>         <span class="c1">#b_fc1 = bias_variable([256])
</span><span class="mi">33</span>         <span class="n">tf</span><span class="p">.</span><span class="n">summary</span><span class="p">.</span><span class="nf">histogram</span><span class="p">(</span><span class="sh">"</span><span class="s">W_fc1</span><span class="sh">"</span><span class="p">,</span> <span class="n">weights</span><span class="p">[</span><span class="sh">'</span><span class="s">wf1</span><span class="sh">'</span><span class="p">])</span>
<span class="mi">34</span>         <span class="n">tf</span><span class="p">.</span><span class="n">summary</span><span class="p">.</span><span class="nf">histogram</span><span class="p">(</span><span class="sh">"</span><span class="s">b_fc1</span><span class="sh">"</span><span class="p">,</span> <span class="n">biases</span><span class="p">[</span><span class="sh">'</span><span class="s">bf1</span><span class="sh">'</span><span class="p">])</span>
<span class="mi">35</span>         <span class="n">h_fc1</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nf">relu</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="nf">matmul</span><span class="p">(</span><span class="n">h_flat</span><span class="p">,</span> <span class="n">weights</span><span class="p">[</span><span class="sh">'</span><span class="s">wf1</span><span class="sh">'</span><span class="p">])</span> <span class="o">+</span> <span class="n">biases</span><span class="p">[</span><span class="sh">'</span><span class="s">bf1</span><span class="sh">'</span><span class="p">])</span>
<span class="mi">36</span>         <span class="n">h_fc1_dropout</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nf">dropout</span><span class="p">(</span><span class="n">h_fc1</span><span class="p">,</span> <span class="n">prob</span><span class="p">)</span>
<span class="mi">37</span>         
<span class="mi">38</span>     <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="nf">name_scope</span><span class="p">(</span><span class="sh">"</span><span class="s">fc_2</span><span class="sh">"</span><span class="p">)</span> <span class="k">as</span> <span class="n">scope</span><span class="p">:</span>
<span class="mi">39</span>         <span class="c1">#W_fc2 = weight_variable([256, NUM_LABELS])
</span><span class="mi">40</span>         <span class="c1">#b_fc2 = bias_variable([NUM_LABELS])
</span><span class="mi">41</span>         <span class="n">tf</span><span class="p">.</span><span class="n">summary</span><span class="p">.</span><span class="nf">histogram</span><span class="p">(</span><span class="sh">"</span><span class="s">W_fc2</span><span class="sh">"</span><span class="p">,</span> <span class="n">weights</span><span class="p">[</span><span class="sh">'</span><span class="s">wf2</span><span class="sh">'</span><span class="p">])</span>
<span class="mi">42</span>         <span class="n">tf</span><span class="p">.</span><span class="n">summary</span><span class="p">.</span><span class="nf">histogram</span><span class="p">(</span><span class="sh">"</span><span class="s">b_fc2</span><span class="sh">"</span><span class="p">,</span> <span class="n">biases</span><span class="p">[</span><span class="sh">'</span><span class="s">bf2</span><span class="sh">'</span><span class="p">])</span>
<span class="mi">43</span>         <span class="c1">#pred = tf.matmul(h_fc1, weights['wf2']) + biases['bf2']
</span><span class="mi">44</span>         <span class="n">pred</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">matmul</span><span class="p">(</span><span class="n">h_fc1_dropout</span><span class="p">,</span> <span class="n">weights</span><span class="p">[</span><span class="sh">'</span><span class="s">wf2</span><span class="sh">'</span><span class="p">])</span> <span class="o">+</span> <span class="n">biases</span><span class="p">[</span><span class="sh">'</span><span class="s">bf2</span><span class="sh">'</span><span class="p">]</span>
<span class="mi">45</span> 
<span class="mi">46</span>     <span class="k">return</span> <span class="n">pred</span>
</code></pre></div></div> <p>tf.summary_histogram is for tensorboard, functions like tf.nn.conv2d, tf.nn.relu, tf.nn.dropout can be found on <a href="https://tensorflow.google.cn/api_docs/" rel="external nofollow noopener" target="_blank">documentation</a>. and some details you might notice is that every part is on there own scope, and bias and weights should be added to regularization loss function for L2 loss.</p> <p>1 def add_to_regularization_loss(W, b): 2 tf.add_to_collection(“losses”, tf.nn.l2_loss(W)) 3 tf.add_to_collection(“losses”, tf.nn.l2_loss(b))</p> <hr> <ul> <li><strong>Main function for data feeding and sess.run</strong></li> </ul> <p>In the main function, not only should we load data (<strong>read_data</strong> function in the EmotionDetectorUtils, you can find this file in the end of this blog), but we also need to make placeholder for variables like <strong>input_dataset</strong> and <strong>input_labels</strong>(since they are assigned by batch data when training),  and <strong>global_step</strong>, which is a vairable we need to mark in every 10 step or 100 step during training.</p> <p>1 global_step = tf.Variable(0, trainable=False) 2 dropout_prob = tf.placeholder(tf.float32) 3 input_dataset = tf.placeholder(tf.float32, [None, IMAGE_SIZE, IMAGE_SIZE, 1],name=”input”) 4 input_labels = tf.placeholder(tf.float32, [None, NUM_LABELS])</p> <p><strong>outside the sess.run</strong>, we should call the emotion_cnn, loss, train function because once we use sess.run and pass the value returned by these function, these function will be automatically called during training time. so remember always put them outside of the <strong>tf.Session() as sess</strong> part.</p> <p>1 pred = emotion_cnn(input_dataset) 2 output_pred = tf.nn.softmax(pred,name=”output”) 3 loss_val = loss(pred, input_labels) 4 train_op = train(loss_val, global_step)</p> <p><strong>inside the sess.run</strong>, we start the training part, first and foremost, global vairable initializer(), remember we have already initialized lots of varaibles, and this function will initialize them all. In the for loop of training, we call <strong>sess.run(train_op, feed_dict = feed_dict)</strong> and feed batch data for every step training, in every 10 steps, we calculate the <strong>Training loss</strong> and print it out, and in every 100 steps, we print out the <strong>validation loss. And other code is about tensorboard and model saver, I will discuss it later on in other blogs.</strong></p> <p>1 with tf.Session() as sess: 2 sess.run(tf.global_variables_initializer()) 3 summary_writer = tf.summary.FileWriter(FLAGS.logs_dir, sess.graph_def) 4 saver = tf.train.Saver() 5 ckpt = tf.train.get_checkpoint_state(FLAGS.logs_dir) 6 if ckpt and ckpt.model_checkpoint_path: 7 saver.restore(sess, ckpt.model_checkpoint_path) 8 print(“Model Restored!”) 9 10 for step in range(MAX_ITERATIONS): 11 batch_image, batch_label = get_next_batch(train_images, train_labels, step) 12 feed_dict = {input_dataset: batch_image, input_labels: batch_label} 13 14 sess.run(train_op, feed_dict=feed_dict) 15 if step % 10 == 0: 16 train_loss, summary_str = sess.run([loss_val, summary_op], feed_dict=feed_dict) 17 summary_writer.add_summary(summary_str, global_step=step) 18 print(“Training Loss: %f” % train_loss) 19 20 if step % 100 == 0: 21 valid_loss = sess.run(loss_val, feed_dict={input_dataset: valid_images, input_labels: valid_labels}) 22 print(“%s Validation Loss: %f” % (datetime.now(), valid_loss)) 23 saver.save(sess, FLAGS.logs_dir + ‘model.ckpt’, global_step=step)</p> <hr> <ul> <li>Result:</li> </ul> <p><img src="https://zhengliangliang.files.wordpress.com/2018/08/fear.jpg" alt="fear.jpg">               <img src="https://zhengliangliang.files.wordpress.com/2018/08/2018-08-24_085215.jpg" alt="2018-08-24_085215.jpg"></p> <p> </p> <p><img src="https://zhengliangliang.files.wordpress.com/2018/08/gavin_fakesmile1.jpg" alt="gavin_fakesmile.jpg">                              <img src="https://zhengliangliang.files.wordpress.com/2018/08/2018-08-24_1008451.jpg" alt="2018-08-24_100845.jpg"></p> <p> </p> <p><img src="https://zhengliangliang.files.wordpress.com/2018/08/smile.jpg" alt="smile.jpg">                           <img src="https://zhengliangliang.files.wordpress.com/2018/08/2018-08-24_100832.jpg" alt="2018-08-24_100832.jpg"></p> <hr> <p>Reference :   DeepLearning With Tensorflow</p> <p>Source code : <a href="https://github.com/ZhengLiangliang1996/EmotionRecognition" rel="external nofollow noopener" target="_blank">Github</a>.</p> <p>Thanks for reading, if there is a mistake on typing or on code, please let me now by leaving a commend below or sending email to zhengliangliang1996@gmail.com.</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/google-gemini-updates-flash-15-gemma-2-and-project-astra/">Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2022/displaying-external-posts-on-your-al-folio-blog/">Displaying External Posts on Your al-folio Blog</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/What-is-Mathematics-CH1-Solution/">What is Mathematics: Solution Chapter 1</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/small-guide-to-supplements-what-you-need-to-know/">A small guide to supplements: What you need to know</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2022/%E6%B7%B7%E4%B9%B1%E4%B8%8E%E7%A7%A9%E5%BA%8F/">混乱与秩序</a> </li> <div id="giscus_thread" style="max-width: 930px; margin: 0 auto;"> <script>let giscusTheme=determineComputedTheme(),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"ZhengLiangliang1996/zhengliangliang1996.github.io","data-repo-id":"","data-category":"Comments","data-category-id":"","data-mapping":"title","data-strict":"1","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":giscusTheme,"data-lang":"en",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,e])=>giscusScript.setAttribute(t,e)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Liangliang Zheng. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="/assets/js/bootstrap-toc.min.js?c82ff4de8b0955d6ff14f5b05eed7eb6"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?06cae41083477f121be8cd9797ad8e2f"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js" integrity="sha256-rjmgmaB99riUNcdlrDtcAiwtLIojSxNyUFdl+Qh+rB4=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-repositories",title:"repositories",description:"",section:"Navigation",handler:()=>{window.location.href="/repositories/"}},{id:"nav-cv",title:"CV",description:"Personal CV, updated on 15 Jun, 2024",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"dropdown-by-year",title:"by year",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"dropdown-by-category",title:"by category",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"post-google-gemini-updates-flash-1-5-gemma-2-and-project-astra",title:"Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra",description:"We\u2019re sharing updates across our Gemini family of models and a glimpse of Project Astra, our vision for the future of AI assistants.",section:"Posts",handler:()=>{window.open("https://blog.google/technology/ai/google-gemini-update-flash-ai-assistant-io-2024/","_blank")}},{id:"post-what-is-mathematics-solution-chapter-1",title:"What is Mathematics: Solution Chapter 1",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/What-is-Mathematics-CH1-Solution/"}},{id:"post-a-small-guide-to-supplements-what-you-need-to-know",title:"A small guide to supplements: What you need to know",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/small-guide-to-supplements-what-you-need-to-know/"}},{id:"post-\u6df7\u4e71\u4e0e\u79e9\u5e8f",title:"\u6df7\u4e71\u4e0e\u79e9\u5e8f",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2022/%E6%B7%B7%E4%B9%B1%E4%B8%8E%E7%A7%A9%E5%BA%8F/"}},{id:"post-podcast-notes-huberman-lab-dopomine",title:"Podcast Notes: Huberman Lab Dopomine",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2022/podcast-notes-huberman-lab-dopomine/"}},{id:"post-displaying-external-posts-on-your-al-folio-blog",title:"Displaying External Posts on Your al-folio Blog",description:"",section:"Posts",handler:()=>{window.open("https://medium.com/@al-folio/displaying-external-posts-on-your-al-folio-blog-b60a1d241a0a?source=rss-17feae71c3c4------2","_blank")}},{id:"post-erc-721",title:"ERC 721",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2022/erc-721/"}},{id:"post-cost-functions-and-its-properties-in-deep-learning-tbc",title:"Cost Functions and its properties in Deep Learning (TBC)",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2022/cost-functions-and-its-properties-in-deep-learning-tbc/"}},{id:"post-cv-modifying",title:"CV: Modifying",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2022/cv-modifying/"}},{id:"post-cheatsheet-pandas-dataframe-commonly-used",title:"Cheatsheet: Pandas, Dataframe, (commonly used)",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2021/cheatsheet-pandas-dataframe-seriescommonly-used/"}},{id:"post-\u4eba\u751f\u4f55\u5904\u4e0d\u6ee5\u60c5",title:"\u4eba\u751f\u4f55\u5904\u4e0d\u6ee5\u60c5",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2021/%E4%BA%BA%E7%94%9F%E4%BD%95%E5%A4%84%E4%B8%8D%E6%BB%A5%E6%83%85/"}},{id:"post-hash-bang-bin-bash-tbc",title:"hash bang/bin/bash (tbc)",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2021/hash-bang-bin-bash-tbc/"}},{id:"post-mit-15-s12-blockchain-and-money-note-lec-7-9-tbc",title:"MIT 15.S12 Blockchain and Money Note (Lec 7~9) tbc",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2021/mit-15-s12-blockchain-and-money-note-lec-79-tbc/"}},{id:"post-mit-15-s12-blockchain-and-money-note-lec-6",title:"MIT 15.S12 Blockchain and Money Note (Lec 6)",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2021/mit-15-s12-blockchain-and-money-note-lec-6-tbc/"}},{id:"post-mit-15-s12-blockchain-and-money-note-lec-5",title:"MIT 15.S12 Blockchain and Money Note (Lec 5)",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2021/mit-15-s12-blockchain-and-money-note-lec-5/"}},{id:"post-awk-sed-grep-\u603b\u7ed3",title:"awk, sed, grep \u603b\u7ed3",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2021/awk-sed-grep-%E6%80%BB%E7%BB%93/"}},{id:"post-mit-15-s12-blockchain-and-money-note-lec-4",title:"MIT 15.S12 Blockchain and Money Note (Lec 4)",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2021/mit-15-s12-blockchain-and-money-note-lec-4/"}},{id:"post-mit-15-s12-blockchain-and-money-note-lec-3",title:"MIT 15.S12 Blockchain and Money Note (Lec 3)",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2021/mit-15-s12-blockchain-and-money-note-lec-3/"}},{id:"post-mit-15-s12-blockchain-and-money-note-lec-2",title:"MIT 15.S12 Blockchain and Money Note (Lec 2)",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2021/mit-15-s12-blockchain-and-money-note-lec-2/"}},{id:"post-mit-15-s12-blockchain-and-money-note-lec-1",title:"MIT 15.S12 Blockchain and Money Note (Lec 1)",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2021/15-s12-blockchain-and-money-note1/"}},{id:"post-\u6d45\u5c1d-39-\u5219-39-\u6b62-\u6b63\u5219",title:"\u6d45\u5c1d'\u5219'\u6b62: \u6b63\u5219",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2021/%E6%B5%85%E5%B0%9D%E5%88%99%E6%AD%A2-%E6%AD%A3%E5%88%99%E4%B8%8E%E5%85%B6%E5%BC%95%E6%93%8E%E5%AE%9E%E7%8E%B0tbc/"}},{id:"post-python\u5de9\u56fa\u6574\u7406",title:"Python\u5de9\u56fa\u6574\u7406",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2021/python%E8%BF%9B%E9%98%B6%E5%B7%A9%E5%9B%BA%E6%95%B4%E7%90%86/"}},{id:"post-\u522b\u867d\u7136\u4f46\u662f\u4e86-2020\u8fc7\u53bb\u4e86",title:"\u522b\u867d\u7136\u4f46\u662f\u4e86\uff0c2020\u8fc7\u53bb\u4e86\uff0e",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2020/%E5%88%AB%E8%99%BD%E7%84%B6%E4%BD%86%E6%98%AF%E4%BA%86-2020%E8%BF%87%E5%8E%BB%E4%BA%86/"}},{id:"post-sql\u89c4\u8303\u4e0e\u6280\u5de7-\u6301\u7eed\u66f4\u65b0",title:"SQL\u89c4\u8303\u4e0e\u6280\u5de7(\u6301\u7eed\u66f4\u65b0)",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2020/sql%E8%A7%84%E8%8C%83%E4%B8%8E%E6%8A%80%E5%B7%A7/"}},{id:"post-\u91d1\u878d\u8bfb\u4e66\u7b14\u8bb0-3",title:"\u91d1\u878d\u8bfb\u4e66\u7b14\u8bb0(3)",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2020/%E9%87%91%E8%9E%8D%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B03/"}},{id:"post-\u91d1\u878d\u8bfb\u4e66\u7b14\u8bb0-2",title:"\u91d1\u878d\u8bfb\u4e66\u7b14\u8bb0(2)",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2020/%E9%87%91%E8%9E%8D%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B02/"}},{id:"post-\u91d1\u878d\u8bfb\u4e66\u7b14\u8bb0-1",title:"\u91d1\u878d\u8bfb\u4e66\u7b14\u8bb0(1)",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2020/%E9%87%91%E8%9E%8D%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B01/"}},{id:"post-gpt-3\u662f\u4ec0\u4e48",title:"GPT-3\u662f\u4ec0\u4e48?",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2020/gpt-3/"}},{id:"post-\u524d\u8111\u767d\u8d28\u5207\u9664\u672f",title:"\u524d\u8111\u767d\u8d28\u5207\u9664\u672f",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2020/%E5%89%8D%E8%84%91%E7%99%BD%E8%B4%A8%E5%88%87%E9%99%A4%E6%9C%AF/"}},{id:"post-personal-github",title:"Personal Github",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2020/person-github/"}},{id:"post-\u6c38\u522b\u4e86\u54402019",title:"\u6c38\u522b\u4e86\u54402019",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2019/%E6%B0%B8%E5%88%AB%E4%BA%86%E5%91%802019/"}},{id:"post-emacs-\u5165\u95e8-\u5360\u5751",title:"Emacs \u5165\u95e8(\u5360\u5751)",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2019/emacs-%E5%85%A5%E9%97%A8%E5%8D%A0%E5%9D%91/"}},{id:"post-\u6211\u5728\u5907\u5fd8\u5f55\u90fd\u5199\u4e9b\u4ec0\u4e48",title:"\u6211\u5728\u5907\u5fd8\u5f55\u90fd\u5199\u4e9b\u4ec0\u4e48\uff1f",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2019/%E6%8C%96%E5%9D%91%E8%BF%87%E5%8E%BB%E7%9A%84%E4%B8%80%E5%B9%B4/"}},{id:"post-adam-vs-radam",title:"Adam vs. RAdam",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2019/%E5%8D%A0%E5%9D%91-adam-vs-radam/"}},{id:"post-\u7855\u58eb\u5f00\u5b66\u7b2c\u4e00\u5b66\u671f-\u5173\u4e8e\u7410\u4e8b\u548c\u5b66\u4e60\u53ca\u65b9\u6cd5",title:"\u7855\u58eb\u5f00\u5b66\u7b2c\u4e00\u5b66\u671f\u2014\u2014\u5173\u4e8e\u7410\u4e8b\u548c\u5b66\u4e60\u53ca\u65b9\u6cd5",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2018/%E7%A1%95%E5%A3%AB%E5%BC%80%E5%AD%A6%E7%AC%AC%E4%B8%80%E5%AD%A6%E6%9C%9F-%E5%85%B3%E4%BA%8E%E7%90%90%E4%BA%8B%E5%92%8C%E5%AD%A6%E4%B9%A0%E5%8F%8A%E6%96%B9%E6%B3%95/"}},{id:"post-emotion-recognition-based-on-tensorflow",title:"Emotion Recognition Based on Tensorflow",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2018/emotion-recognition-based-on-tensorflow/"}},{id:"post-python-review-amp-amp-some-simple-algorithms",title:"Python_review &amp; Some simple algorithms",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2018/python_review-some-simple-algorithms/"}},{id:"post-nlp-word2vec-skip-gram-cs224n-implemented-in-raw-way-and-in-tensorflow",title:"NLP: Word2Vec Skip-Gram(CS224n) implemented in raw way and in Tensorflow",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2018/nlp-word2vec-skip-gramcs224n/"}},{id:"post-cs231n-assignment3-image-captioning-with-rnns",title:"CS231n Assignment3_Image Captioning with RNNs",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2018/cs231n-assignment3_image-captioning-with-rnns/"}},{id:"post-pytorch-vs-tensorflow",title:"Pytorch VS Tensorflow",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2018/pytorch-vs-tensorflow/"}},{id:"post-cs231n-cnn-notes-amp-amp-assignment2",title:"CS231N_CNN_Notes&amp;Assignment2",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2018/cs231n_cnn_notesassignment2/"}},{id:"post-web-crawler\u722ctop100\u7535\u5f71\u4fe1\u606f",title:"Web_Crawler\u722ctop100\u7535\u5f71\u4fe1\u606f",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2018/web_crawler%E7%88%ACtop100%E7%94%B5%E5%BD%B1%E4%BF%A1%E6%81%AF/"}},{id:"post-\u725b\u5ba2\u7b97\u6cd5\u76f4\u64ad\u9898\u76ee\u603b\u7ed3day2t1234",title:"\u725b\u5ba2\u7b97\u6cd5\u76f4\u64ad\u9898\u76ee\u603b\u7ed3Day2T1234",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2017/%E7%89%9B%E5%AE%A2%E7%AE%97%E6%B3%95%E7%9B%B4%E6%92%AD%E9%A2%98%E7%9B%AE%E6%80%BB%E7%BB%93day2t1234/"}},{id:"post-\u725b\u5ba2\u7b97\u6cd5\u76f4\u64ad\u9898\u76ee\u603b\u7ed3day1t234",title:"\u725b\u5ba2\u7b97\u6cd5\u76f4\u64ad\u9898\u76ee\u603b\u7ed3Day1T234",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2017/%E7%89%9B%E5%AE%A2%E7%AE%97%E6%B3%95%E7%9B%B4%E6%92%AD%E9%A2%98%E7%9B%AE%E6%80%BB%E7%BB%93day1t234%E9%9B%B6%E5%92%8C%E5%8D%9A%E5%BC%88/"}},{id:"post-\u725b\u5ba2\u7b97\u6cd5\u76f4\u64ad\u9898\u76ee\u603b\u7ed3day1t1-\u96f6\u548c\u535a\u5f08",title:"\u725b\u5ba2\u7b97\u6cd5\u76f4\u64ad\u9898\u76ee\u603b\u7ed3Day1T1(\u96f6\u548c\u535a\u5f08)",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2017/%E7%89%9B%E5%AE%A2%E7%AE%97%E6%B3%95%E7%9B%B4%E6%92%AD%E9%A2%98%E7%9B%AE%E6%80%BB%E7%BB%93/"}},{id:"post-java\u5b66\u4e60\u7b14\u8bb0-\u516d-\u88c5\u9970-\u89c2\u5bdf\u8005\u6a21\u5f0f\u53ca\u76d1\u542c\u5668",title:"Java\u5b66\u4e60\u7b14\u8bb0(\u516d):\u88c5\u9970\u3001\u89c2\u5bdf\u8005\u6a21\u5f0f\u53ca\u76d1\u542c\u5668",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2017/java%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%85%AD%E8%A3%85%E9%A5%B0-%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F%E5%8F%8A%E7%9B%91%E5%90%AC%E5%99%A8/"}},{id:"post-java\u5b66\u4e60\u7b14\u8bb0-\u56db-filter",title:"Java\u5b66\u4e60\u7b14\u8bb0(\u56db):Filter",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2017/java%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%9B%9Bfilter/"}},{id:"post-java\u5b66\u4e60\u7b14\u8bb0-\u4e94-\u6587\u4ef6\u7684\u4e0a\u4f20\u548c\u4e0b\u8f7d",title:"Java\u5b66\u4e60\u7b14\u8bb0(\u4e94):\u6587\u4ef6\u7684\u4e0a\u4f20\u548c\u4e0b\u8f7d",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2017/java%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%BA%94%E6%96%87%E4%BB%B6%E7%9A%84%E4%B8%8A%E4%BC%A0%E5%92%8C%E4%B8%8B%E8%BD%BD/"}},{id:"post-jdbc\u5b66\u4e60\u7b14\u8bb0-\u4e09",title:"JDBC\u5b66\u4e60\u7b14\u8bb0(\u4e09)",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2017/jdbc%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%B8%89/"}},{id:"post-jdbc\u5b66\u4e60\u7b14\u8bb0-\u4e8c",title:"JDBC\u5b66\u4e60\u7b14\u8bb0(\u4e8c)",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2017/jdbc%E7%AC%94%E8%AE%B0%E4%BA%8C/"}},{id:"post-jdbc\u5b66\u4e60\u7b14\u8bb0-\u4e00",title:"JDBC\u5b66\u4e60\u7b14\u8bb0(\u4e00)",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2017/jdbc%E7%AC%94%E8%AE%B0%E5%8F%8A%E5%85%B6%E4%BB%96/"}},{id:"post-j2ee-cookie\u4e0esession\u77e5\u8bc6\u70b9\u56de\u987e",title:"J2EE_Cookie\u4e0eSession\u77e5\u8bc6\u70b9\u56de\u987e",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2017/j2ee_cookie%E4%B8%8Esession%E7%9F%A5%E8%AF%86%E7%82%B9%E5%9B%9E%E9%A1%BE/"}},{id:"post-bug-\u89e3\u51b3-nginx-502-bad-gateway",title:"Bug\uff1a\u89e3\u51b3 nginx 502 Bad GateWay",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2017/bug-%E8%A7%A3%E5%86%B3-nginx-502-bad-gateway/"}},{id:"post-windows-laravel\u73af\u5883\u90e8\u7f72",title:"Windows Laravel\u73af\u5883\u90e8\u7f72",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2016/windows-laravel%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/"}},{id:"post-git\u57fa\u7840\u8bb0\u5f55",title:"Git\u57fa\u7840\u8bb0\u5f55",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2016/git%E5%9F%BA%E7%A1%80%E8%AE%B0%E5%BD%95/"}},{id:"post-\u7b97\u6cd5\u5bfc\u8bba\u8bfb\u4e66\u7b14\u8bb0-6",title:"\u7b97\u6cd5\u5bfc\u8bba\u8bfb\u4e66\u7b14\u8bb0(6)",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2016/%E7%AE%97%E6%B3%95%E5%AF%BC%E8%AE%BA%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B06/"}},{id:"post-qt\u5b9e\u73b0\u7535\u5b50\u8bcd\u5178gui-project",title:"QT\u5b9e\u73b0\u7535\u5b50\u8bcd\u5178GUI\uff08project\uff09",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2016/qt%E5%AE%9E%E7%8E%B0%E7%94%B5%E5%AD%90%E8%AF%8D%E5%85%B8gui-project/"}},{id:"post-\u7b97\u6cd5\u5bfc\u8bba\u8bfb\u4e66\u7b14\u8bb0-5",title:"\u7b97\u6cd5\u5bfc\u8bba\u8bfb\u4e66\u7b14\u8bb0(5)",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2016/%E7%AE%97%E6%B3%95%E5%AF%BC%E8%AE%BA%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B05/"}},{id:"post-\u7b97\u6cd5\u5bfc\u8bba\u8bfb\u4e66\u7b14\u8bb0-4",title:"\u7b97\u6cd5\u5bfc\u8bba\u8bfb\u4e66\u7b14\u8bb0(4)",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2016/%E7%AE%97%E6%B3%95%E5%AF%BC%E8%AE%BA%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B04/"}},{id:"post-\u7b97\u6cd5\u5bfc\u8bba\u8bfb\u4e66\u7b14\u8bb0-3",title:"\u7b97\u6cd5\u5bfc\u8bba\u8bfb\u4e66\u7b14\u8bb0(3)",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2016/%E7%AE%97%E6%B3%95%E5%AF%BC%E8%AE%BA%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B03/"}},{id:"post-\u7b97\u6cd5\u5bfc\u8bba\u8bfb\u4e66\u7b14\u8bb0-2",title:"\u7b97\u6cd5\u5bfc\u8bba\u8bfb\u4e66\u7b14\u8bb0(2)",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2016/%E7%AE%97%E6%B3%95%E5%AF%BC%E8%AE%BA%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B02/"}},{id:"post-aws\u514d\u8d39\u670d\u52a1\u5668\u7533\u8bf7\u548c\u4e2d\u7ee7\u5668\u642d\u5efa",title:"AWS\u514d\u8d39\u670d\u52a1\u5668\u7533\u8bf7\u548c\u4e2d\u7ee7\u5668\u642d\u5efa",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2016/aws%E5%85%8D%E8%B4%B9%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%94%B3%E8%AF%B7%E5%92%8C%E4%B8%AD%E7%BB%A7%E5%99%A8%E6%90%AD%E5%BB%BA/"}},{id:"post-\u7b97\u6cd5\u5bfc\u8bba\u8bfb\u4e66\u7b14\u8bb0-1",title:"\u7b97\u6cd5\u5bfc\u8bba\u8bfb\u4e66\u7b14\u8bb0\uff081\uff09",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2016/%E7%AE%97%E6%B3%95%E5%AF%BC%E8%AE%BA%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-1/"}},{id:"post-\u6570\u636e\u7ed3\u6784\u4e4b-\u6392\u5e8f",title:"\u6570\u636e\u7ed3\u6784\u4e4b\u2014\u2014\u6392\u5e8f",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2015/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B-%E6%8E%92%E5%BA%8F/"}},{id:"post-\u6570\u636e\u7ed3\u6784\u4e4b-\u56fe",title:"\u6570\u636e\u7ed3\u6784\u4e4b\u2014\u2014\u56fe",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2015/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B-%E5%9B%BE/"}},{id:"post-stl\u4e4bvector\u7528\u6cd5",title:"STL\u4e4bVector\u7528\u6cd5",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2015/stl%E4%B9%8Bvector%E7%94%A8%E6%B3%95/"}},{id:"post-\u6570\u636e\u7ed3\u6784\u4e4b-\u6811",title:"\u6570\u636e\u7ed3\u6784\u4e4b\u2014\u2014\u6811",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2015/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B-%E6%A0%91/"}},{id:"post-\u56de\u6eaf\u6cd5\u7ecf\u5178\u5e94\u7528-n\u7687\u540e-amp-amp-\u8ff7\u5bab\u95ee\u9898",title:"\u56de\u6eaf\u6cd5\u7ecf\u5178\u5e94\u7528\u2014\u2014N\u7687\u540e&amp;\u8ff7\u5bab\u95ee\u9898",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2015/%E5%9B%9E%E6%BA%AF%E6%B3%95%E7%BB%8F%E5%85%B8%E5%BA%94%E7%94%A8-n%E7%9A%87%E5%90%8E%E8%BF%B7%E5%AE%AB%E9%97%AE%E9%A2%98/"}},{id:"post-\u6570\u636e\u7ed3\u6784\u4e4b-\u961f\u5217",title:"\u6570\u636e\u7ed3\u6784\u4e4b\u2014\u2014\u961f\u5217",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2015/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B-%E9%98%9F%E5%88%97/"}},{id:"post-\u6570\u636e\u7ed3\u6784\u4e4b-\u6808",title:"\u6570\u636e\u7ed3\u6784\u4e4b\u2014\u2014\u6808",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2015/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B-%E6%A0%88/"}},{id:"post-\u5927\u4e8c\u7b2c\u4e00\u5b66\u671f\u8ba1\u5212-\u5907\u8868\u53ca\u5176\u4ed6",title:"\u5927\u4e8c\u7b2c\u4e00\u5b66\u671f\u8ba1\u5212/\u5907\u8868\u53ca\u5176\u4ed6",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2015/%E5%A4%A7%E4%BA%8C%E7%AC%AC%E4%B8%80%E5%AD%A6%E6%9C%9F%E8%AE%A1%E5%88%92%E5%A4%87%E8%A1%A8%E5%8F%8A%E5%85%B6%E4%BB%96/"}},{id:"post-\u5229\u7528\u9753\u6c64beautifulsoup4\u5199\u4e00\u4e2a\u7b80\u6613\u722c\u866b",title:"\u5229\u7528\u9753\u6c64BeautifulSoup4\u5199\u4e00\u4e2a\u7b80\u6613\u722c\u866b",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2015/%E5%88%A9%E7%94%A8%E9%9D%93%E6%B1%A4beautifulsoup4%E5%86%99%E4%B8%80%E4%B8%AA%E7%AE%80%E6%98%93%E7%88%AC%E8%99%AB/"}},{id:"post-\u6570\u636e\u7ed3\u6784\u4e4b-\u94fe\u8868",title:"\u6570\u636e\u7ed3\u6784\u4e4b\u2014\u2014\u94fe\u8868",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2015/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B-%E9%93%BE%E8%A1%A8/"}},{id:"post-\u6570\u636e\u7ed3\u6784\u4e4b-\u5411\u91cf",title:"\u6570\u636e\u7ed3\u6784\u4e4b\u2014\u2014\u5411\u91cf",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2015/vector/"}},{id:"news-a-simple-inline-announcement-with-markdown-emoji-sparkles-smile",title:'A simple inline announcement with Markdown emoji! <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> <img class="emoji" title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20">',description:"",section:"News"},{id:"news-a-long-announcement-with-details",title:"A long announcement with details",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_2/"}},{id:"news-a-simple-inline-announcement",title:"A simple inline announcement.",description:"",section:"News"},{id:"projects-project-1",title:"project 1",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-project-2",title:"project 2",description:"a project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"projects-project-3-with-very-long-name",title:"project 3 with very long name",description:"a project that redirects to another website",section:"Projects",handler:()=>{window.location.href="/projects/3_project/"}},{id:"projects-project-4",title:"project 4",description:"another without an image",section:"Projects",handler:()=>{window.location.href="/projects/4_project/"}},{id:"projects-project-5",title:"project 5",description:"a project with a background image",section:"Projects",handler:()=>{window.location.href="/projects/5_project/"}},{id:"projects-project-6",title:"project 6",description:"a project with no image",section:"Projects",handler:()=>{window.location.href="/projects/6_project/"}},{id:"projects-project-7",title:"project 7",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/7_project/"}},{id:"projects-project-8",title:"project 8",description:"an other project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/8_project/"}},{id:"projects-project-9",title:"project 9",description:"another project with an image \ud83c\udf89",section:"Projects",handler:()=>{window.location.href="/projects/9_project/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%7A%68%65%6E%67%6C%69%61%6E%67%6C%69%61%6E%67%31%39%39%37@%67%6D%61%69%6C.%63%6F%6D","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("/feed.xml","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js"></script> </body> </html>